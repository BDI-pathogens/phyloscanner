z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
z
z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
quantiles	<- c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)
z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
z
ans			<- copy(z)
daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)
daggregateTo
daggregateTo$TR_TARGETCAT
control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)
z			<- copy(mca)	#
	z[, TR_GENDER:= 'Any']#
	z[, TR_MIGRANT:= TR_TARGETCAT]#
	z			<- z[, list(TR_MIGRANT=TR_MIGRANT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_GENDER','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
z
ans			<- rbind(ans,z)
daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^[a-z]+:([FM]):.*','\\1', TR_TRM_CATEGORY),#
									':',#
									gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)#
									)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]
daggregateTo
set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)
z[, TR_GENDER:= gsub('^([FM]):([0-1])','\\1', TR_TARGETCAT)]#
	z[, TR_MIGRANT:= gsub('^([FM]):([0-1])','\\2', TR_TARGETCAT)]
z
z			<- z[, list(TR_MIGRANT=TR_MIGRANT, TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
z
ans			<- rbind(ans,z)
ans
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')
tmp
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_GENDER, levels=c('0','1'), labels=c('resident','in-migrant'))]#
	tmp[, TR:= paste0(TR_GENDER,', ',TR_MIGRANT)]
tmp
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrant'))]#
	tmp[, TR:= paste0(TR_GENDER,', ',TR_MIGRANT)]
tmp
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1)) +#
			facet_grid(~REC_TARGETCAT)
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrating'))]#
	tmp[, TR:= paste0(TR_MIGRANT,', ',TR_GENDER)]
tmp
tmp[, TR:= paste0(TR_MIGRANT,' ',TR_GENDER)]
tmp
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1)) +#
			facet_grid(~REC_TARGETCAT)
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')
tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')
ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=10, h=5, useDingbats=FALSE)
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=10, h=5, useDingbats=FALSE)
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.5) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=10, h=5, useDingbats=FALSE)
ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=10, h=8, useDingbats=FALSE)
ans
tmp			<- subset(ans, TR_MIGRANT=='Any')
tmp
tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]	#
	tmp[, TR:= TR_GENDER]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group')
ggsave(file=gsub('\\.rda','_sourcesByGender.pdf',mcmc.file), w=10, h=8, useDingbats=FALSE)
tmp
tmp			<- subset(ans, TR_MIGRANT=='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]	#
	tmp[, TR:= TR_GENDER]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
ggsave(file=gsub('\\.rda','_sourcesByGender.pdf',mcmc.file), w=8, h=6, useDingbats=FALSE)
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrating'))]#
	tmp[, TR:= paste0(TR_MIGRANT,' ',TR_GENDER)]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=8, h=6, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=4, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=5, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)
tmp			<- subset(ans, TR_MIGRANT=='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]	#
	tmp[, TR:= TR_GENDER]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGender.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)
tmp
tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrating'))]#
	tmp[, TR:= paste0(TR_MIGRANT,' ',TR_GENDER)]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]
tmp
daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= 'Any']#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)
daggregateTo
control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)
mca
z			<- copy(mca)	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_TARGETCAT')]
z
z			<- dcast.data.table(z, REC_TARGETCAT+TR_TARGETCAT~P, value.var='Q')
z
daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1))))]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control			<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')
daggregateTo
mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)
mca
z			<- copy(mca)#
	z[, FLOW:= paste0(TR_TARGETCAT,' -> ',REC_TARGETCAT)]#
	set(z, z[, which(TR_TARGETCAT=='inland' & REC_TARGETCAT=='inland')], 'FLOW', 'within')#
	set(z, z[, which(TR_TARGETCAT=='fishing' & REC_TARGETCAT=='fishing')], 'FLOW', 'within')
z
z			<- z[, list(VALUE=sum(VALUE)), by=c('FLOW','SAMPLE')]
z
z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('FLOW')]
z
z			<- dcast.data.table(z, FLOW~P, value.var='Q')
z
set(z, NULL, 'FLOW', z[, factor(FLOW, levels=rev(c('within','inland -> fishing','fishing -> inland','external -> fishing','external -> inland')))])
z
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(x='\nestimated transmission flowsn\n(adjusted for sampling)') +
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(x='\nestimated transmission flowsn\n(adjusted for sampling)')
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(x='\nestimated transmission flowsn\n(adjusted for sampling)') +#
			coord_flip()
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flowsn\n(adjusted for sampling)') +#
			coord_flip()
z[, ANA:='transmission flows']
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)') +#
			coord_flip() +#
			facet_grid(~ANA)
ggplot(z) +#
			geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() +#
			facet_grid(~ANA)
ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.5) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() +#
			facet_grid(~ANA)
ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.25) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() +#
			facet_grid(~ANA)
ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=6, h=3, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=6, h=2, useDingbats=FALSE)
ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.25) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_classic() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() +#
			facet_grid(~ANA)			#
	ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=6, h=2, useDingbats=FALSE)
ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.25) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_classic() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() 			#
	ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=6, h=2, useDingbats=FALSE)
indir	<- '~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run'#
	infiles	<- list.files(indir, pattern='aggregatedFishInland|prAreas')#
	infiles	<- infiles[grepl('conf60',infiles) & grepl('opt112401',infiles) & grepl('flowsetc',infiles) & !grepl('beforeSort',infiles) ]
infiles
as.data.table(read.csv("~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401_aggregatedFishInland_flowsetc.csv"))
z		<- as.data.table(read.csv("~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401_aggregatedFishInland_flowsetc.csv"))
z
z		<- subset(z, STAT=='flow ratio')
z
z		<- as.data.table(read.csv("~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401_aggregatedFishInland_flowsetc.csv")) #
	z		<- subset(z, STAT=='flow_ratio')
z
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/500, 1/100, 1/50,1/20,1/10,1/4,1/2,1,2,4,10,20,50,100, 500), labels=c('1/500','1/100','1/50','1/20','1/10','1/4','1/2','1','2','4','10','20','50','100','500')) +#
			labs(x= '\nflows inland->fishing / flows fishing->inland', y='') +#
			coord_cartesian(xlim=c(1/500,500)) +#
			theme_bw() +#
			theme(axis.title.y=element_blank(),#
					axis.text.y=element_blank(),#
					axis.ticks.y=element_blank(),#
					#panel.grid.major.x=element_blank(),#
					panel.grid.minor.x=element_blank(),#
					panel.grid.major.y=element_blank())
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nflows inland->fishing / flows fishing->inland', y='') +#
			coord_cartesian(xlim=c(1/500,500)) +#
			theme_classic()
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nflows inland->fishing / flows fishing->inland', y='') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic()
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nflow ratio') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic()
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nflow ratio', y='') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic() #
	ggsave(file=gsub('\\.rda','_flowRatioOverall.pdf',mcmc.file), w=6, h=2, useDingbats=FALSE)
ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nestimated flow ratio', y='') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic() #
	ggsave(file=gsub('\\.rda','_flowRatioOverall.pdf',mcmc.file), w=6, h=2, useDingbats=FALSE)
z			<- copy(mca)#
	z[, FLOW:= paste0(TR_TARGETCAT,' -> ',REC_TARGETCAT)]#
	set(z, z[, which(TR_TARGETCAT=='inland' & REC_TARGETCAT=='inland')], 'FLOW', 'within')#
	set(z, z[, which(TR_TARGETCAT=='fishing' & REC_TARGETCAT=='fishing')], 'FLOW', 'within')	#
	z			<- z[, list(VALUE=sum(VALUE)), by=c('FLOW','SAMPLE')]#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('FLOW')]#
	z			<- dcast.data.table(z, FLOW~P, value.var='Q')#
	set(z, NULL, 'FLOW', z[, factor(FLOW, levels=rev(c('within','inland -> fishing','fishing -> inland','external -> fishing','external -> inland')))])#
	z[, ANA:='transmission flows']#
	ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.25) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_classic() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() 			#
	ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=4, h=2, useDingbats=FALSE)
ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=5, h=2, useDingbats=FALSE)
z		<- as.data.table(read.csv("~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401_aggregatedFishInland_flowsetc.csv")) #
	z		<- subset(z, STAT=='flow_ratio')	#
	ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nestimated flow ratio', y='') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic() #
	ggsave(file=gsub('\\.rda','_flowRatioOverall.pdf',mcmc.file), w=5, h=2, useDingbats=FALSE)
z			<- copy(mca)#
	z[, FLOW:= paste0(TR_TARGETCAT,' -> ',REC_TARGETCAT)]#
	set(z, z[, which(TR_TARGETCAT=='inland' & REC_TARGETCAT=='inland')], 'FLOW', 'within')#
	set(z, z[, which(TR_TARGETCAT=='fishing' & REC_TARGETCAT=='fishing')], 'FLOW', 'within')	#
	z			<- z[, list(VALUE=sum(VALUE)), by=c('FLOW','SAMPLE')]#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('FLOW')]#
	z			<- dcast.data.table(z, FLOW~P, value.var='Q')#
	set(z, NULL, 'FLOW', z[, factor(FLOW, levels=rev(c('within','inland -> fishing','fishing -> inland','external -> fishing','external -> inland')))])
z
rtr3
infile.inference	<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	mcmc.file			<- '~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda'#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- 1#
	opt$adjust.participation.bias		<- 1#
	opt$migration.def.code				<- '24'#
	opt$set.missing.migloc.to.inland	<- 0#
	opt$set.missing.migloc.to.fishing	<- 1-opt$set.missing.migloc.to.inland#
	load(infile.inference)
rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	##
	#	calculate observed number of transmissions#
	##
	dobs	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobs, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]#
	quantiles	<- c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)#
	#	aggregate MCMC output to flows #
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1))))]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control			<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)
z			<- copy(mca)#
	z[, FLOW:= paste0(TR_TARGETCAT,' -> ',REC_TARGETCAT)]
z
z			<- z[, list(VALUE=sum(VALUE)), by=c('FLOW','SAMPLE')]#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('FLOW')]#
	z			<- dcast.data.table(z, FLOW~P, value.var='Q')
z
z			<- copy(mca)#
	z[, FLOW:= paste0(TR_TARGETCAT,' -> ',REC_TARGETCAT)]#
	set(z, z[, which(TR_TARGETCAT=='inland' & REC_TARGETCAT=='inland')], 'FLOW', 'within')#
	set(z, z[, which(TR_TARGETCAT=='fishing' & REC_TARGETCAT=='fishing')], 'FLOW', 'within')	#
	z			<- z[, list(VALUE=sum(VALUE)), by=c('FLOW','SAMPLE')]#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('FLOW')]#
	z			<- dcast.data.table(z, FLOW~P, value.var='Q')#
	set(z, NULL, 'FLOW', z[, factor(FLOW, levels=rev(c('within','inland -> fishing','fishing -> inland','external -> fishing','external -> inland')))])#
	z[, ANA:='transmission flows']
z
ggplot(z) +#
			geom_point(aes(x=FLOW, y=M)) +#
			geom_errorbar(aes(x=FLOW, ymin=CL, ymax=CU), width=0.25) +#
			#geom_boxplot(aes(x=FLOW, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50') +#
			theme_classic() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			labs(y='\nestimated transmission flows\n(adjusted for sampling)', x='') +#
			coord_flip() 			#
	ggsave(file=gsub('\\.rda','_flowsOverall.pdf',mcmc.file), w=5, h=2, useDingbats=FALSE)	#
	z		<- as.data.table(read.csv("~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401_aggregatedFishInland_flowsetc.csv")) #
	z		<- subset(z, STAT=='flow_ratio')	#
	ggplot(z, aes(y=STAT)) + 			#
			geom_vline(xintercept=1, lty=2) +#
			geom_point(aes(x=M), size=2) +#
			geom_errorbarh(aes(xmin=CL, xmax=CU), height=0.4) +#
			scale_x_log10(expand=c(0,0), breaks=c(1/10,1/4,1/2,1,2,4,10), labels=c('1/10','1/4','1/2','1','2','4','10')) +#
			labs(x= '\nestimated flow ratio', y='') +#
			coord_cartesian(xlim=c(1/10,10)) +#
			theme_classic() #
	ggsave(file=gsub('\\.rda','_flowRatioOverall.pdf',mcmc.file), w=5, h=2, useDingbats=FALSE)
infile.inference	<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	mcmc.file			<- '~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda'#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- 1#
	opt$adjust.participation.bias		<- 1#
	opt$migration.def.code				<- '24'#
	opt$set.missing.migloc.to.inland	<- 0#
	opt$set.missing.migloc.to.fishing	<- 1-opt$set.missing.migloc.to.inland#
	load(infile.inference)#
	##
	#	prepare data on observed transmission flows#
	##
	#	subset to variables needed, using RTR3	#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	##
	#	calculate observed number of transmissions#
	##
	dobs	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobs, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]#
	quantiles	<- c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)#
	#	aggregate MCMC output to sources by gender #
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= 'Any']#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_TARGETCAT')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_TARGETCAT~P, value.var='Q')#
	z[, TR_GENDER:= TR_TARGETCAT]#
	z[, TR_MIGRANT:= 'Any']#
	z			<- z[, list(TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_MIGRANT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	#	aggregate MCMC output to sources by gender and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= TR_TARGETCAT]#
	z[, TR_MIGRANT:= 'Any']#
	z			<- z[, list(TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_MIGRANT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- copy(z)#
	#	aggregate MCMC output to sources by migration status and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= 'Any']#
	z[, TR_MIGRANT:= TR_TARGETCAT]#
	z			<- z[, list(TR_MIGRANT=TR_MIGRANT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_GENDER','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- rbind(ans,z)#
	#	aggregate MCMC output to sources by migration status+gender and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^[a-z]+:([FM]):.*','\\1', TR_TRM_CATEGORY),#
					':',#
					gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)#
			)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= gsub('^([FM]):([0-1])','\\1', TR_TARGETCAT)]#
	z[, TR_MIGRANT:= gsub('^([FM]):([0-1])','\\2', TR_TARGETCAT)]#
	z			<- z[, list(TR_MIGRANT=TR_MIGRANT, TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- rbind(ans,z)#
	tmp			<- subset(ans, TR_MIGRANT=='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]	#
	tmp[, TR:= TR_GENDER]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGender.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)	#
	tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrating'))]#
	tmp[, TR:= paste0(TR_MIGRANT,' ',TR_GENDER)]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)
infile.inference	<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	mcmc.file			<- '~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda'#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- 1#
	opt$adjust.participation.bias		<- 1#
	opt$migration.def.code				<- '24'#
	opt$set.missing.migloc.to.inland	<- 0#
	opt$set.missing.migloc.to.fishing	<- 1-opt$set.missing.migloc.to.inland#
	load(infile.inference)#
	##
	#	prepare data on observed transmission flows#
	##
	#	subset to variables needed, using RTR3	#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	##
	#	calculate observed number of transmissions#
	##
	dobs	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobs, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]#
	quantiles	<- c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)#
	#	aggregate MCMC output to sources by gender #
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= 'Any']#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)
z
z			<- dcast.data.table(z, REC_TARGETCAT+TR_TARGETCAT~P, value.var='Q')
z[, TR_GENDER:= TR_TARGETCAT]#
	z[, TR_MIGRANT:= 'Any']#
	z			<- z[, list(TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_MIGRANT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')
z
#	aggregate MCMC output to sources by gender and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= TR_TARGETCAT]#
	z[, TR_MIGRANT:= 'Any']#
	z			<- z[, list(TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_MIGRANT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- copy(z)#
	#	aggregate MCMC output to sources by migration status and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= 'Any']#
	z[, TR_MIGRANT:= TR_TARGETCAT]#
	z			<- z[, list(TR_MIGRANT=TR_MIGRANT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','TR_GENDER','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- rbind(ans,z)#
	#	aggregate MCMC output to sources by migration status+gender and inland/fish#
	daggregateTo	<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^[a-z]+:([FM]):.*','\\1', TR_TRM_CATEGORY),#
					':',#
					gsub('.*:([0-9])$','\\1',daggregateTo$TR_TRM_CATEGORY)#
			)]#
	daggregateTo[, REC_TARGETCAT:= gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1))))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)	#
	control		<- list(	burnin.p=0.05, #
			thin=NA_integer_, #
			regex_pars='PI')#
	mca			<- source.attribution.mcmc.aggregateToTarget(mcmc.file, daggregateTo, control=control)	#
	z			<- copy(mca)	#
	z[, TR_GENDER:= gsub('^([FM]):([0-1])','\\1', TR_TARGETCAT)]#
	z[, TR_MIGRANT:= gsub('^([FM]):([0-1])','\\2', TR_TARGETCAT)]#
	z			<- z[, list(TR_MIGRANT=TR_MIGRANT, TR_GENDER=TR_GENDER, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]	#
	z			<- z[, list(P=names(quantiles), Q=unname(quantile(VALUE, p=quantiles))), by=c('REC_TARGETCAT','TR_MIGRANT','TR_GENDER')]#
	z			<- dcast.data.table(z, REC_TARGETCAT+TR_MIGRANT+TR_GENDER~P, value.var='Q')#
	ans			<- rbind(ans,z)#
	tmp			<- subset(ans, TR_MIGRANT=='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]	#
	tmp[, TR:= TR_GENDER]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGender.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)	#
	tmp			<- subset(ans, TR_MIGRANT!='Any' & TR_GENDER!='Any')#
	tmp[, TR_GENDER:= factor(TR_GENDER, levels=c('M','F'), labels=c('men','women'))]#
	tmp[, TR_MIGRANT:= factor(TR_MIGRANT, levels=c('0','1'), labels=c('resident','in-migrating'))]#
	tmp[, TR:= paste0(TR_MIGRANT,' ',TR_GENDER)]#
	tmp[, REC_TARGETCAT:= factor(REC_TARGETCAT, levels=c('fishing','inland'), labels=c('sources of transmissions\nin RCCS fishing communities','sources of transmissions\nin RCCS inland communities'))]#
	ggplot(tmp) +#
			geom_boxplot(aes(x=TR, ymin=CL, ymax=CU, lower=IL, upper=IU, middle=M), stat='identity', fill='grey50', width=0.7) +#
			theme_bw() +#
			scale_y_continuous(labels=scales:::percent, lim=c(0,1), expand=c(0,0)) +#
			facet_grid(~REC_TARGETCAT) +#
			labs(x='\ntransmitter group') +#
			theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))#
	ggsave(file=gsub('\\.rda','_sourcesByGenderAndMigration.pdf',mcmc.file), w=6, h=6, useDingbats=FALSE)
ans
infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"
infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"
infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"
outfile.base						<- gsub('.rda$','',infile.inference.mcmc)#
	tmp									<- gsub('.*_opt([0-9]+).*','\\1',outfile.base)#
	#tmp									<- "112401"#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- as.integer(substr(tmp,1,1))#
	opt$adjust.participation.bias		<- as.integer(substr(tmp,2,2))#
	opt$migration.def.code				<- substr(tmp,3,4)#
	opt$set.missing.migloc.to.inland	<- as.integer(substr(tmp,5,5))#
	opt$set.missing.migloc.to.fishing	<- as.integer(substr(tmp,6,6))#
	cat('\ninfile.inference=',infile.inference.data)#
	cat('\ninfile.inference.mcmc=',infile.inference.mcmc)#
	cat('\ninfile.subdistricts=',infile.subdistricts)#
	cat('\nopt=',unlist(opt))			#
	##
	#	prepare data on observed transmission flows#
	##
	load(infile.inference.data)#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}	#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))	#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )	#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	calculate observed number of transmissions#
	dobsRCCS	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobsRCCS, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobsRCCS[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobsRCCS))]#
	##
	# 	prepare data on fishing / inland areas#
	#		#
	darea	<- desm[, list(ELIGIBLE=sum(PART_EVER+PART_NEVER)), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])
darea
load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, FEMALE_COUNT:= popcount_15_49-male_count]#
	rasdata	<- subset(rasdata, select=c(pop_class, latitude, longitude, male_count,  FEMALE_COUNT))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	tmp		<- rasdata[, list(F=round(sum(FEMALE_COUNT),d=0), M=round(sum(MALE_COUNT),d=0)), by='AREA']#
	tmp		<- melt(tmp, id.vars='AREA', value.name='POP_EST', variable.name='SEX')#
	set(tmp, NULL, 'AREA', tmp[, gsub('Fishing','fishing',gsub('Inland','inland',AREA))])#
	darea	<- merge(tmp, darea, by=c('AREA','SEX'))#
	dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	dprior[, P:= pmin(1,ELIGIBLE/POP_EST)]#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	set(dprior, NULL, c('AREA','SEX','ELIGIBLE','POP_EST'), NULL)
dprior
darea
load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)
rasdata
desm
darea	<- desm[, list(	ELIGIBLE=sum(PART_EVER+PART_NEVER),#
							HIV_1516_YES=sum(HIV_1516_YES)#
							), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])
darea
rasdata
load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, latitude, longitude, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))
rasdata
load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	rasdata	<- melt(rasdata, id.vars='AREA')
rasdata
rasdata	<- rasdata[, list(EST=round(sum(value),d=0)), by=c('AREA','variable')]
rasdata
darea
rasdata[, SEX:= gsub('([A-Z]+)_([A-Z])','\\2',variable)]
rasdata
set(rasdata, NULL, 'AREA', rasdata[, gsub('Fishing','fishing',gsub('Inland','inland',AREA))])
rasdata
set(rasdata, NULL, 'AREA', rasdata[, tolower(AREA)])
rasdata
rasdata[, variable:= gsub('([A-Z]+)_([A-Z])','\\1',variable)]
rasdata
rasdata	<- dcast.data.table(rasdata, AREA+SEX~variable, value.var='EST')
rasdata
merge(rasdata, darea, by=c('AREA','SEX'))
darea	<- merge(rasdata, darea, by=c('AREA','SEX'))
darea
dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	dprior[, P_POP:= pmin(1,ELIGIBLE/POPCOUNT)]#
	dprior[, P_HIV:= pmin(1,HIV_1516_YES/HIVCOUNT)]#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]
dprior
dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]
dprior
opt$predict.with.infcounts			<- 1#
	opt$predict.inflation				<- 20
dprior
opt
if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		setnames(dprior, 'P_HIV', 'P')#
	}#
	if(predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		setnames(dprior, 'P_POP', 'P')#
	}
dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		setnames(dprior, 'P_HIV', 'P')#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		setnames(dprior, 'P_POP', 'P')#
	}
dprior
darea
dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		setnames(dprior, 'P_HIV', 'P')#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		setnames(dprior, 'P_POP', 'P')#
	}
dprior
dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))
dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		dprior[, P:= pmin(1, P_HIV)]		#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		dprior[, P:= pmin(1, P_POP)]#
	}	#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]
dprior
dprior	<- subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))
dprior
gsub('\\.rda','_PI.csv',mcmc.file)
paste(opt)
paste(opt,collapse='')
outfile.base						<- gsub('.rda$','',infile.inference.mcmc)
outfile.base
paste0(outfile.base, opt$predict.with.infcounts, opt$predict.inflation, '_prAreas.rda')
RakaiFull.phylogeography.190327.predict.areaflows<- function(infile.inference.data=NULL, infile.inference.mcmc=NULL, infile.subdistricts=NULL, predict.with.infcounts=1, predict.inflation=10)#
{	#
	#predict.with.infcounts<- 1; predict.inflation<- 10#
	require(data.table)	#
	require(gtools)	#
	if(is.null(infile.inference.data))	#
		infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	if(is.null(infile.inference.mcmc))#
		infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"	#
	if(is.null(infile.subdistricts))		#
		infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	outfile.base						<- gsub('.rda$','',infile.inference.mcmc)#
	tmp									<- gsub('.*_opt([0-9]+).*','\\1',outfile.base)#
	#tmp									<- "112401"#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- as.integer(substr(tmp,1,1))#
	opt$adjust.participation.bias		<- as.integer(substr(tmp,2,2))#
	opt$migration.def.code				<- substr(tmp,3,4)#
	opt$set.missing.migloc.to.inland	<- as.integer(substr(tmp,5,5))#
	opt$set.missing.migloc.to.fishing	<- as.integer(substr(tmp,6,6))#
	opt$predict.with.infcounts			<- predict.with.infcounts#
	opt$predict.inflation				<- predict.inflation#
	cat('\ninfile.inference=',infile.inference.data)#
	cat('\ninfile.inference.mcmc=',infile.inference.mcmc)#
	cat('\ninfile.subdistricts=',infile.subdistricts)#
	cat('\nopt=',unlist(opt))			#
	##
	#	prepare data on observed transmission flows#
	##
	load(infile.inference.data)#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}	#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))	#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )	#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	calculate observed number of transmissions#
	dobsRCCS	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobsRCCS, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobsRCCS[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobsRCCS))]#
	##
	# 	prepare data on fishing / inland areas#
	#		#
	darea	<- desm[, list(	ELIGIBLE=sum(PART_EVER+PART_NEVER),#
							HIV_1516_YES=sum(HIV_1516_YES)#
							), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])#
	load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	rasdata	<- melt(rasdata, id.vars='AREA')#
	rasdata	<- rasdata[, list(EST=round(sum(value),d=0)), by=c('AREA','variable')]#
	set(rasdata, NULL, 'AREA', rasdata[, tolower(AREA)])#
	rasdata[, SEX:= gsub('([A-Z]+)_([A-Z])','\\2',variable)]#
	rasdata[, variable:= gsub('([A-Z]+)_([A-Z])','\\1',variable)]#
	rasdata	<- dcast.data.table(rasdata, AREA+SEX~variable, value.var='EST')#
	darea	<- merge(rasdata, darea, by=c('AREA','SEX'))#
	dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		dprior[, P:= pmin(1, P_HIV)]		#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		dprior[, P:= pmin(1, P_POP)]#
	}	#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	dprior	<- subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))#
	##
	#	make csv table for supplement#
	if(0)#
	{#
		df	<- unique(subset(dsubdis, select=c(AREA, SUBDISTRICT, SEX, COMM_NUM_A, COMM_ELIGIBLE, MAP_POPCOUNT)))	#
		df	<- df[, list(MAP_POPCOUNT=round(MAP_POPCOUNT[1]), RCCS_ELIGIBLE=sum(COMM_ELIGIBLE), RCCS_ELIGIBLE_P=sum(COMM_ELIGIBLE)/MAP_POPCOUNT[1], N_COMM=length(unique(COMM_NUM_A))), by=c('AREA','SUBDISTRICT','SEX')]#
		setkey(df, AREA, SUBDISTRICT, SEX )#
		df[, RCCS_LABEL:= paste0(RCCS_ELIGIBLE,' (',round(RCCS_ELIGIBLE_P*100,d=1),'%)')]#
		write.csv( subset(df, select=c(AREA, SUBDISTRICT, SEX, MAP_POPCOUNT, N_COMM, RCCS_LABEL)), row.names=FALSE, file=gsub('\\.rda','_table.csv',infile.subdistricts))#
	}#
	#	flows that we expect:#
	if(0)#
	{#
		s		<- c(0.2363956, 0.2631666, 0.3919308, 0.5427133)#
		s		<- c(0.16, 0.18, 1, 1)#
		pi		<- c(0.243,0.029,0.039,0.231,0.184,0.006,0.039,0.127)#
		pi		<- pi/sum(pi)#
		pistar	<- c( 	pi[1]/s[4]/s[3],  pi[2]/s[4]/s[1],  pi[3]/s[2]/s[3], pi[4]/s[2]/s[1],#
						pi[5]/s[3]/s[4],  pi[6]/s[3]/s[2],  pi[7]/s[1]/s[4], pi[8]/s[1]/s[2])#
		pistar <- pistar/sum(pistar)#
		c( (pistar[1]+pistar[5]), (pistar[2]+pistar[6]), (pistar[3]+pistar[7]), (pistar[4]+pistar[8]) )#
		(pistar[3]+pistar[7]) / (pistar[2]+pistar[6]) #
		# 'Fish:M','Fish:F',#
	}#
	##
	#	aggregate MCMC samples to areas #
	#	#
	daggregateTo	<- subset(dobsRCCS, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY))]#
	daggregateTo[, REC_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$REC_TRM_CATEGORY))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)		#
	control	<- list(	burnin.p=0.05, #
						thin=NA_integer_, #
						regex_pars='*')#
	mca		<- source.attribution.mcmc.aggregateToTarget(infile.inference.mcmc, daggregateTo, control=control)#
	mca		<- subset(mca, !grepl('external',TR_TARGETCAT))#
	setnames(mca, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs	<- unique(subset(mca, select=c(TR_TRM_CAT, REC_TRM_CAT)))#
	setkey(dobs, TR_TRM_CAT, REC_TRM_CAT)#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]	#
	mca		<- merge(dobs, mca, by=c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs[, TR_SAMPLING_CATEGORY:= TR_TRM_CAT]#
	dobs[, REC_SAMPLING_CATEGORY:= REC_TRM_CAT]#
	##
	#	run MCMC#
	##
	set.seed(42)#
	pp.n			<- 1e4#
	pp.burnin		<- 0.9#
	pp.sweeps		<- 1e2#
	mc				<- list()#
	mc[['pars']]	<- list()#
	mc$pars$Z_RCCS	<- matrix(NA, nrow=pp.n, ncol=nrow(dobs))#
	mc[['pp']]		<- vector('list',pp.n)#
	for(i in 1:pp.n)#
	{#
		##
		# 	sample Z among RCCS communities, and add to dobs as 'TRM_OBS'#
		##
		dobs[, TRM_OBS:=NULL]#
		tmp					<- subset(mca, VARIABLE=='Z' & SAMPLE==sample(max(mca$SAMPLE), 1))#
		setnames(tmp, 'VALUE', 'TRM_OBS')#
		tmp					<- subset(tmp, select=c(TRM_CAT_PAIR_ID, TRM_OBS))#
		dobs				<- merge(dobs, tmp, by='TRM_CAT_PAIR_ID')#
		cat('\nIteration', i,'\nSetting Z among RCCS communities to', dobs$TRM_OBS)#
		mc$pars$Z_RCCS[i,]	<- dobs$TRM_OBS#
		##
		#	run MCMC and return#
		##
		control			<- list( mcmc.n=9*pp.sweeps, verbose=0 )#
		mc[['pp']][[i]]	<- source.attribution.mcmc(dobs, dprior, control=control)#
		mc[['pp']][[i]][['it.info']][, PP_IT:= i]#
		gc()#
	}#
	#	collect variables and save#
	for(x in c('XI','XI_LP','S','S_LP','Z','PI','N'))#
		mc$pars[[x]]	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['pars']][[x]][seq.int(pp.sweeps*pp.burnin+1, pp.sweeps),,drop=FALSE]) )#
	mc$it.info	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['it.info']][seq.int(9*pp.sweeps*pp.burnin+1, 9*pp.sweeps),] ) )		#
	mc$dl		<- mc[['pp']][[1]][['dl']] #
	mc$dlt		<- mc[['pp']][[1]][['dlt']] #
	mc$dlu		<- mc[['pp']][[1]][['dlu']]#
	mc$time		<- sum(sapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['time']] ))#
	mc[['pp']]	<- NULL#
	str(mc[[1]])#
	gc()	#
	mcmc.file	<- paste0(outfile.base, opt$predict.with.infcounts, opt$predict.inflation, '_prAreas.rda')#
	save(mc, dobsRCCS, dprior, dsubdis, daggregateTo, file=mcmc.file)#
	#	MCMC diagnostics#
	control		<- list(	burnin.p=0, #
			regex_pars='PI', #
			credibility.interval=0.95, #
			pdf.plot.all.parameters=TRUE, #
			pdf.plot.n.worst.case.parameters=0, #
			pdf.height.per.par=1.2, #
			outfile.base=gsub('\\.rda','',mcmc.file))#
	source.attribution.mcmc.diagnostics(mcmc.file, control=control)	#
	# 	make data.table in long format and calculate key quantities#
	colnames(mc$pars[['PI']])	<- paste0('PI-',seq_len(ncol(mc$pars[['PI']])))#
	pars	<- as.data.table(mc$pars[['PI']])#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
	tmp		<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CAT, REC_TRM_CAT))#
	setnames(tmp, c('TR_TRM_CAT','REC_TRM_CAT'), c('TR_TARGETCAT','REC_TARGETCAT'))#
	pars	<- merge(pars, tmp, by='TRM_CAT_PAIR_ID')#
	set(pars, NULL, c('TRM_CAT_PAIR_ID','variable'), NULL)#
	setnames(pars, colnames(pars), toupper(colnames(pars)))#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','_PIGender.csv',mcmc.file))		#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland:M/fishing:M', 'inland:M fishing:F', 'fishing:M inland:F'), c('inland:F/fishing:F', 'inland:F fishing:M', 'fishing:F inland:M')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PIGender.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PIGender.csv',mcmc.file), control)#
	#	aggregate to fish<->inland#
	setnames(pars, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	pars[, TR_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',TR_TRM_CAT)]#
	pars[, REC_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',REC_TRM_CAT)]#
	pars	<- pars[, list(VALUE=sum(VALUE)), by=c('TR_TARGETCAT','REC_TARGETCAT','VARIABLE','SAMPLE')]#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','PI.csv',mcmc.file))#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland/fishing', 'inland fishing', 'fishing inland')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PI.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PI.csv',mcmc.file), control)	#
}
lddirichlet_vector	<- function(x, nu){#
	ans	<- sum((nu - 1) * log(x)) + sum(lgamma(nu)) - lgamma(sum(nu))#
	stopifnot(is.finite(ans))#
	ans#
}#
#
#' @title Source attribution while adjusting for sampling bias#
#' @export#
#' @import data.table#
#' @importFrom gtools rdirichlet#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param dobs Data.table of observed number of transmission events for each transmission pair category.#
#' @param dprior Data.table of draws from the prior distribution of sampling probabilities.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"seed"}{Random number seed, for reproducibility.}#
#'  \item{"mcmc.n"}{Guide on the number of MCMC iterations. The actual number of iterations will be slightly larger, and a multiple of the number of iterations needed to complete one MCMC sweep through all free parameters.}#
#'  \item{"verbose"}{Flag to switch on/off verbose output.}#
#'  \item{"outfile"}{Full path name to which the MCMC output is saved to in RDA format, in an object called \code{mc}.}#
#' }#
#' @return NULL. MCMC output is written to an RDA file.#
source.attribution.mcmc	<- function(dobs, dprior, control=list(seed=42, mcmc.n=1e3, verbose=1, outfile='SAMCMCv190327.rda')){#
  #library(data.table); library(gtools)#
#
  dmode <- function(x) {#
    den <- density(x, kernel=c("gaussian"))#
    (den$x[den$y==max(den$y)])#
  }#
  ##
  # basic checks#
  ##
  if(!all(dobs$TR_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for TR_SAMPLING_CATEGORY')#
  if(!all(dobs$REC_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for REC_SAMPLING_CATEGORY')#
#
  ptm	<- Sys.time()#
  if('seed'%in%names(control))#
  {#
	  cat('\nSetting seed to',control$seed)#
	  set.seed(control$seed)#
  }#
#
  ##
  # set up mcmc#
  ##
  mc				<- list()#
  #	determine if the sampling probabilities are <1.#
  # If they are NOT, Z will be the same as TRM_OBS, and the algorithm only updates PI#
  mc$with.sampling	<- dprior[, list(ALL_ONE=all(P==1)), by='SAMPLING_CATEGORY'][, !all(ALL_ONE)]#
  mc$time			<- NA_real_#
  # construct look-up table so we know which transmission pair categories need to be updated#
  # at every MCMC iteration#
  tmp				<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_SAMPLING_CATEGORY, REC_SAMPLING_CATEGORY))#
  tmp				<- melt(tmp, id.vars='TRM_CAT_PAIR_ID', value.name='SAMPLING_CATEGORY', variable.name='WHO')#
  #	make data.table with unique sampling categories#
  mc$dlu			<- unique(subset(tmp, select=c(WHO, SAMPLING_CATEGORY)))#
  mc$dlu[, UPDATE_ID:= seq_len(nrow(mc$dlu))]#
  setkey(mc$dlu, UPDATE_ID)#
  # make data.table that maps UPDATE_IDs to TRM_CAT_PAIR_IDs#
  mc$dl				<- merge(mc$dlu, tmp, by=c('WHO','SAMPLING_CATEGORY'))#
  setkey(mc$dl, UPDATE_ID)#
  #	every transmission category pair needs to be updated at least one as we sweep through the sampling categories#
  # I don t think this is guaranteed, hence the check#
  if( !all(dobs$TRM_CAT_PAIR_ID %in% sort(unique(mc$dl$TRM_CAT_PAIR_ID))) )#
	  stop('Fatal error. Contact the package maintainer with your input data.')#
  # make data.table that maps TRM_CAT_PAIR_IDs to transmitter UPDATE_IDs and recipient UPDATE_IDs#
  mc$dlt			<- dcast.data.table(mc$dl, TRM_CAT_PAIR_ID~WHO, value.var='UPDATE_ID')#
  setnames(mc$dlt, c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY'), c('TR_UPDATE_ID','REC_UPDATE_ID'))#
  mc$dlt			<- merge(mc$dlt,subset(dobs,select=c('TRM_CAT_PAIR_ID','TRM_OBS')),by='TRM_CAT_PAIR_ID')#
  setkey(mc$dlt,TRM_CAT_PAIR_ID)#
#
  # make indexed lookup table for speed#
  update.info	<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
	  update.info[[i]]	<- mc$dl[UPDATE_ID==i,TRM_CAT_PAIR_ID]#
  }#
  # make indexed prior samples for speed#
  setkey(dprior,SAMPLING_CATEGORY)#
  dprior2		<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
    tmp				<- mc$dlu[UPDATE_ID==i,SAMPLING_CATEGORY]#
    dprior2[[i]]<-dprior[J(tmp),nomatch=0L]#
  }#
#
  dprior3   <- dprior[,list(EST_SAMPLING_RATE=dmode(P)),by=SAMPLING_CATEGORY]#
  dobs2   <- subset(dobs,select = c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY','TRM_CAT_PAIR_ID'))#
  setnames(dprior3,colnames(dprior3),paste0('TR_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='TR_SAMPLING_CATEGORY')#
  setnames(dprior3,colnames(dprior3),gsub('TR_','REC_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='REC_SAMPLING_CATEGORY')#
  dobs2[,EST_SAMPLING_RATE:=TR_EST_SAMPLING_RATE * REC_EST_SAMPLING_RATE]#
#
  mc$nprior			<- max(dprior$SAMPLE)#
  mc$sweep			<- nrow(mc$dlu)+1L#
  mc$nsweep			<- ceiling( control$mcmc.n/mc$sweep )#
  mc$n				<- mc$nsweep*mc$sweep#
  mc$pars			<- list()#
  mc$pars$LAMBDA	<- matrix(NA_real_, ncol=nrow(dobs), nrow=1)		#prior for proportions#
  mc$pars$XI		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # prior for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$XI_LP		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # log prior density for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$S			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # prior probability of sampling transmission pair categories#
  mc$pars$S_LP		<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # log prior density of sampling transmission pair categories#
  mc$pars$Z			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) #augmented data#
  mc$pars$NU		<- NA_real_															#prior for N#
  mc$pars$N			<- matrix(NA_integer_, ncol=1, nrow=mc$nsweep+1L)							#total number of counts on augmented data#
  mc$pars$PI		<- matrix(NA_real_, ncol=nrow(dobs), nrow=mc$nsweep+1L)	#proportions#
  mc$it.info		<- data.table(	IT= seq.int(0,mc$n),#
									PAR_ID= rep(NA_integer_, mc$n+1L),#
									BLOCK= rep(NA_character_, mc$n+1L),#
									MHRATIO= rep(NA_real_, mc$n+1L),#
									ACCEPT=rep(NA_integer_, mc$n+1L),#
									LOG_LKL=rep(NA_real_, mc$n+1L),#
									LOG_PRIOR=rep(NA_real_, mc$n+1L))#
#
  if(1)#
  {#
	  cat('\nNumber of parameters:\t', ncol(mc$pars$PI)+ncol(mc$pars$N)+ncol(mc$pars$Z)+ncol(mc$pars$S)+ncol(mc$pars$XI) )#
	  cat('\nDimension of PI:\t', ncol(mc$pars$PI))#
	  cat('\nSweep length:\t', mc$sweep)#
	  cat('\nNumber of sweeps:\t', mc$nsweep)#
	  cat('\nNumber of iterations:\t', mc$n)#
	  tmp				<- mc$dl[, list(N_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
	  cat('\nNumber of transmission pair categories updated per iteration, and their frequencies:\n')#
	  print(table(tmp$N_PAIRS))#
  }#
  ##
  # initialise MCMC#
  ##
  mc$curr.it			<- 1L#
  set(mc$it.info, mc$curr.it, 'BLOCK', 'INIT')#
  set(mc$it.info, mc$curr.it, 'PAR_ID', 0L)#
  set(mc$it.info, mc$curr.it, 'MHRATIO', 1)#
  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
  #	prior lambda: use the Berger objective prior with minimal loss compared to marginal Beta reference prior#
  #	(https://projecteuclid.org/euclid.ba/1422556416)#
  mc$pars$LAMBDA[1,]	<- 0.8/nrow(dobs)#
  # prior for sampling in transmitter categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='TR_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in in recipient categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='REC_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in transmission pair categories#
  mc$pars$S[1,]			<- mc$pars$XI[1, mc$dlt$TR_UPDATE_ID] * mc$pars$XI[1, mc$dlt$REC_UPDATE_ID]#
  mc$pars$S_LP[1,]		<- mc$pars$XI_LP[1, mc$dlt$TR_UPDATE_ID] + mc$pars$XI_LP[1, mc$dlt$REC_UPDATE_ID]#
  #	augmented data: proposal draw under sampling probability#
  mc$pars$Z[1,]			<- dobs$TRM_OBS + rnbinom(nrow(dobs),dobs$TRM_OBS,mc$pars$S[1,])#
  #	prior nu: set Poisson rate to the expected augmented counts, under average sampling probability#
  mc$pars$NU			<- sum(dobs$TRM_OBS) / mean(dobs2$EST_SAMPLING_RATE)#
  #	total count: that s just the sum of Z#
  mc$pars$N[1,]			<- sum(mc$pars$Z[1,])#
  #	proportions: draw from full conditional#
  mc$pars$PI[1,]		<- rdirichlet(1, mc$pars$Z[1,] + mc$pars$LAMBDA[1,])#
  #	store log likelihood#
  tmp	<- sum( dbinom(dobs$TRM_OBS, size=mc$pars$Z[1,], prob=mc$pars$S[1,], log=TRUE) ) +#
    dmultinom(mc$pars$Z[1,], size=mc$pars$N[1,], prob=mc$pars$PI[1,], log=TRUE)#
  set(mc$it.info, 1L, 'LOG_LKL', tmp)#
  # 	store log prior#
  tmp	<- dpois(mc$pars$N[1,], lambda=mc$pars$NU, log=TRUE) +#
    		lddirichlet_vector(mc$pars$PI[1,], nu=mc$pars$LAMBDA[1,]) +#
    		sum(mc$pars$S_LP[1,])#
  set(mc$it.info, 1L, 'LOG_PRIOR', tmp)#
  # parameter value at the current step#
  XI.curr	<- mc$pars$XI[1,]#
  XI_LP.curr<- mc$pars$XI_LP[1,]#
  S.curr	<- mc$pars$S[1,]#
  S_LP.curr	<- mc$pars$S_LP[1,]#
  PI.curr	<- mc$pars$PI[1,]#
  N.curr	<- mc$pars$N[1,]#
  Z.curr	<- mc$pars$Z[1,]#
#
  # run mcmc#
  options(warn=0)#
  for(i in 1L:mc$n)#
  {#
    mc$curr.it		<- i#
    # determine source-recipient combination that will be updated in this iteration#
    update.count	<- (i-1L) %% mc$sweep + 1L#
    update.round 	<- (i-1L) %/% mc$sweep + 1L#
	# update in one go S, Z, N for the ith XI#
    if(mc$with.sampling & update.count<mc$sweep)#
    {#
	  # update.info	<- subset(mc$dl, UPDATE_ID==update.count)	# recompute for each sweep + the category and the pair id#
      update.cat	<- mc$dlu$SAMPLING_CATEGORY[update.count]#
      update.pairs	<- update.info[[update.count]]#
#
      # propose single XI#
	  XI.prop		<- XI.curr#
	  XI_LP.prop	<- XI_LP.curr#
	  tmp			<- dprior2[[update.count]][sample(mc$nprior,1),]#
	  if(tmp$SAMPLING_CATEGORY[1]!=update.cat)#
		  stop('\nFatal error in dprior2.')#
	  XI.prop[ update.count ]	<- tmp$P#
	  XI_LP.prop[ update.count ]<- tmp$LP#
	  # propose all S that involve the one XI from above#
	  S.prop						<- S.curr#
	  S_LP.prop						<- S_LP.curr#
	  S.prop[update.pairs]			<- XI.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] * XI.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  S_LP.prop[update.pairs]		<- XI_LP.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] + XI_LP.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  # propose all Z that involve a new S#
	  Z.prop						<- Z.curr#
	  Z.prop[update.pairs]			<- mc$dlt$TRM_OBS[update.pairs] + rnbinom(length(update.pairs), mc$dlt$TRM_OBS[update.pairs], S.prop[update.pairs])#
	  # propose total of Z#
	  N.prop						<- sum(Z.prop)#
	  #	calculate MH ratio#
	  log.prop.ratio	<- sum(dnbinom(Z.curr[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.curr[update.pairs], log=TRUE)) -#
						   sum(dnbinom(Z.prop[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.prop[update.pairs], log=TRUE))#
	  log.fc			<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.curr[update.pairs], prob=S.curr[update.pairs], log=TRUE)) +#
						   dmultinom(Z.curr, prob=PI.curr, log=TRUE) +#
						   dpois(N.curr, lambda=mc$pars$NU, log=TRUE)#
	  log.fc.prop		<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.prop[update.pairs], prob=S.prop[update.pairs], log=TRUE)) +#
			  			   dmultinom(Z.prop, prob=PI.curr, log=TRUE) +#
			  			   dpois(N.prop, lambda=mc$pars$NU, log=TRUE)#
	  log.mh.ratio		<- log.fc.prop - log.fc + log.prop.ratio#
	  mh.ratio			<- min(1,exp(log.mh.ratio))#
	  #	update#
	  mc$curr.it		<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'S-Z-N')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', update.count)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', mh.ratio)#
	  accept 			<- as.integer(runif(1) < mh.ratio)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', accept)#
#
	  if(control$verbose & accept)#
	  {#
		  cat('\nit ',mc$curr.it,' ACCEPT S-Z-N block ',update.count)#
	  }#
	  if(accept)#
	  {#
		  XI.curr	<- XI.prop#
		  XI_LP.curr<- XI_LP.prop#
		  S.curr	<- S.prop#
		  S_LP.curr	<- S_LP.prop#
		  Z.curr	<- Z.prop#
		  N.curr	<- N.prop#
	  }#
    }#
#
    # update PI#
    if(!mc$with.sampling | update.count==mc$sweep)#
    {#
      #	propose#
      PI.prop		<- rdirichlet(1L, Z.curr + mc$pars$LAMBDA[1,])#
      #	this is the full conditional of PI given S, N, Z#
      #	always accept#
      #	update#
	  mc$curr.it	<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'PI')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', NA_integer_)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', 1L)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
      PI.curr		<- PI.prop#
#
	  # at the end of sweep, record current parameters#
      mc$pars$XI[update.round+1L,]		<- XI.curr#
	  mc$pars$XI_LP[update.round+1L,]	<- XI_LP.curr#
      mc$pars$S[update.round+1L,]		<- S.curr#
	  mc$pars$S_LP[update.round+1L,]	<- S_LP.curr#
      mc$pars$Z[update.round+1L,]		<- Z.curr#
      mc$pars$N[update.round+1L,]		<- N.curr#
      mc$pars$PI[update.round+1L,]		<- PI.curr#
    }#
#
	# 	record log likelihood#
	tmp	<- sum(dbinom(dobs$TRM_OBS, size=Z.curr, prob=S.curr, log=TRUE) ) +#
	    		dmultinom(Z.curr, size=N.curr, prob=PI.curr, log=TRUE)#
	set(mc$it.info, mc$curr.it, 'LOG_LKL', tmp)#
	# 	record log prior#
	tmp	<- dpois(N.curr, lambda=mc$pars$NU, log=TRUE) +#
	  			lddirichlet_vector(PI.curr, nu=mc$pars$LAMBDA[1,]) +#
			  	sum(S_LP.curr)#
	set(mc$it.info, mc$curr.it, 'LOG_PRIOR', tmp)#
	##
	if(update.count==mc$sweep & update.round %% 100 == 0){#
		cat('\nSweeps done:\t',update.round)#
	}#
  }#
#
  mc$time	<- Sys.time()-ptm#
  if(!'outfile'%in%names(control))#
	  return(mc)#
  save(mc,	file=control$outfile)#
  NULL#
}#
#
#' @title Aggregate MCMC output to target parameters#
#' @export#
#' @import data.table#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param daggregateTo Data.table that maps the categories of transmission pairs used in the MCMC to lower-dimensional categories that are of primary interest.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"thin"}{Thin MCMC output to every nth MCMC iteration.}#
#'  \item{"regex_pars"}{Regular expression to select the parameters that are to be aggregated.}#
#'  \item{"outfile"}{Full file name of the output csv file.}#
#' }#
#' @return NULL. Monte Carlo samples are written to a csv file.#
source.attribution.mcmc.aggregateToTarget	<- function(mcmc.file, daggregateTo, control=list(burnin.p=NA_real_, thin=NA_integer_, regex_pars='*', outfile=gsub('\\.rda','_aggregated.csv',mcmc.file))){#
	#	basic checks#
	if(!'data.table'%in%class(daggregateTo))#
		stop('daggregateTo is not a data.table')#
	if(!all(c('TRM_CAT_PAIR_ID','TR_TARGETCAT','REC_TARGETCAT')%in%colnames(daggregateTo)))#
		stop('daggregateTo does not contain one of the required columns TRM_CAT_PAIR_ID, TR_TARGETCAT, REC_TARGETCAT')#
#
	#	load MCMC output#
	cat('\nLoading MCMC output...')#
	load(mcmc.file)#
#
	#	define internal control variables#
	burnin.p	<- control$burnin.p#
	if(is.na(burnin.p))#
		burnin.p<- 0#
	burnin.n	<- floor(burnin.p*nrow(mc$pars$S))#
	thin		<- control$thin#
	if(is.na(thin))#
		thin	<- 1#
#
	#	collect parameters#
	cat('\nCollecting parameters...')#
	pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
	if(grepl(control$regex_pars,'Z'))#
	{#
		tmp	<- mc$pars$Z#
		colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
	if(grepl(control$regex_pars,'PI'))#
	{#
		tmp	<- mc$pars$PI#
		colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
#
	# remove burn-in#
	if(burnin.n>0)#
	{#
		cat('\nRemoving burnin in set to ', 100*burnin.p,'% of chain, total iterations=',burnin.n)#
		tmp		<- seq.int(burnin.n,nrow(mc$pars$S))#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	# thin#
	if(thin>1)#
	{#
		cat('\nThinning to every', thin,'th iteration')#
		tmp		<- seq.int(1,nrow(pars),thin)#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	cat('\nMaking aggregated MCMC output...')#
	# make data.table in long format#
	pars	<- as.data.table(pars)#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
#
	# aggregate MCMC samples#
	if(!all(sort(unique(pars$TRM_CAT_PAIR_ID))==sort(unique(daggregateTo$TRM_CAT_PAIR_ID))))#
		stop('The transmission count categories in the MCMC output do not match the transmission count categories in the aggregateTo data table.')#
	pars	<- merge(pars, daggregateTo, by='TRM_CAT_PAIR_ID')#
	pars	<- pars[, list(VALUE=sum(value)), by=c('VARIABLE','TR_TARGETCAT','REC_TARGETCAT','SAMPLE')]#
#
	# save or return#
	if(!'outfile'%in%names(control))#
		return(pars)#
	if(grepl('csv$',control$outfile))#
	{#
		cat('\nWriting csv file to',control$outfile)#
		write.csv(pars, row.names=FALSE, file=control$outfile)#
	}#
	if(grepl('rda$',control$outfile))#
	{#
		cat('\nSaving rda file to',control$outfile)#
		save(pars, file=control$outfile)#
	}#
}#
#
#' @title Estimate Flows, Sources, WAIFM, Flow ratios#
#' @export#
#' @import data.table#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param infile Full file name to aggregated MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the derivation of key quantities:#
#' \itemize{#
#'  \item{"quantiles"}{Named list of quantiles. Default: c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)}#
#'  \item{"flowratios"}{Cector of length 3. First element: name of flow ratio. Second element: name of transmission pair category for enumerator of flow ratio. Third element: name of transmission pair category for denominator of flow ratio.}#
#'  \item{"outfile"}{Full file name for output csv file.}#
#' }#
#' @return NULL. A csv file is written to disk.#
source.attribution.aggmcmc.getKeyQuantities<- function(infile, control)#
{#
	cat('\nReading aggregated MCMC output...')#
	pars		<- as.data.table(read.csv(infile, stringsAsFactors=FALSE))#
	pars		<- subset(pars, VARIABLE=='PI')#
	if(any(is.na(pars$VALUE)))#
	{#
		cat('\nRemoving NA output for samples n=', nrow(subset(pars, is.na(VALUE))))#
		pars		<- subset(pars, !is.na(VALUE))#
	}#
	cat('\nComputing flows...')#
	#	calculate flows#
	z		<- pars[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='flows']#
	ans		<- copy(z)#
	gc()#
#
	cat('\nComputing WAIFM...')#
	#	calculate WAIFM#
	z		<- pars[, list(REC_TARGETCAT=REC_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('TR_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='waifm']#
	ans		<- rbind(ans,z)#
	gc()#
#
	cat('\nComputing sources...')#
	#	calculate sources#
	z		<- pars[, list(TR_TARGETCAT=TR_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, REC_TARGETCAT, TR_TARGETCAT )#
	z[, STAT:='sources']#
	ans		<- rbind(ans,z)#
	gc()#
#
	if(length(control$flowratios)>0)#
	{#
		cat('\nComputing flow ratios...')#
		#	calculate transmission flow ratios#
		z		<- copy(pars)#
		z[, FLOW:=paste0(TR_TARGETCAT,' ',REC_TARGETCAT)]#
		z		<- dcast.data.table(z, SAMPLE~FLOW, value.var='VALUE')#
		set(z, NULL, colnames(z)[!colnames(z)%in%c('SAMPLE',unlist(control$flowratios))], NULL)#
		for(ii in seq_along(control$flowratios))#
		{#
			if(!control$flowratios[[ii]][2]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][2],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][2], 0)#
			}#
			if(!control$flowratios[[ii]][3]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][3],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][3], 0)#
			}#
			set(z, NULL, control$flowratios[[ii]][1], z[[ control$flowratios[[ii]][2] ]] /  z[[ control$flowratios[[ii]][3] ]])#
			set(z, NULL, c(control$flowratios[[ii]][2],control$flowratios[[ii]][3]), NULL)#
		}#
		z		<- melt(z, id.vars='SAMPLE', value.name='VALUE', variable.name='FLOWRATIO_CAT')#
		z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('FLOWRATIO_CAT')]#
		z		<- dcast.data.table(z, FLOWRATIO_CAT~P, value.var='Q')#
		z[, LABEL:= paste0(round(M, d=2), '\n[',round(CL,d=2),' - ',round(CU,d=2),']')]#
		z[, LABEL2:= paste0(round(M, d=2), ' (',round(CL,d=2),'-',round(CU,d=2),')')]#
		z[, STAT:='flow_ratio']#
		ans		<- rbind(ans,z, fill=TRUE)#
		gc()#
	}#
#
	cat('\nWriting output to',control$outfile)#
	write.csv(ans, row.names=FALSE,file=control$outfile)#
}#
#' @title MCMC diagnostics for the source attribution algorithm#
#' @export#
#' @import data.table#
#' @import ggplot2#
#' @importFrom bayesplot mcmc_trace mcmc_acf_bar mcmc_hist#
#' @importFrom coda mcmc effectiveSize#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"regex_pars"}{Regular expression to select the parameter names for which diagnostics are computed. The default is all parameters, which is '*'.}#
#'  \item{"credibility.interval"}{Width of the marginal posterior credibility intervals.}#
#'  \item{"pdf.plot.n.worst.case.parameters"}{Integer which specifies the number of parameters with smallest effective sample size that are inspected in detail. If set to 0, worst case analyses are not performed.}#
#'  \item{"pdf.plot.all.parameters"}{Flag which specifies if traces shall be plotted for all parameters. If set to TRUE, very large pdfs may be created.}#
#'  \item{"pdf.height.per.par"}{Most plots show diagnostics with parameters listed on the y-axis. This value controls the plot height in inches for each free parameter.}#
#'  \item{"outfile.base"}{Start of the full file name for all output files.}#
#' }#
#' @return NULL. Diagnostic plots and csv files are written to disk.#
source.attribution.mcmc.diagnostics	<- function(mcmc.file, control=list(burnin.p=0.2, regex_pars='*', credibility.interval=0.95, pdf.plot.n.worst.case.parameters=10, pdf.plot.all.parameters=FALSE, pdf.height.per.par=1.2, outfile.base=gsub('\\.rda','',mcmc.file))){#
  #library(coda); library(data.table); library(bayesplot); library(ggplot2)#
#
  cat('\nLoading MCMC output...')#
  load(mcmc.file)#
#
  burnin.n	<- floor(control$burnin.p*nrow(mc$pars$S))#
#
  cat('\nCollecting parameters...')#
  pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
  if(grepl(control$regex_pars,'S'))#
  {#
	  tmp	<- mc$pars$S#
	  colnames(tmp)	<- paste0('S-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'Z'))#
  {#
	  tmp	<- mc$pars$Z#
	  colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'N'))#
  {#
	  tmp	<- mc$pars$N#
	  colnames(tmp)	<- paste0('N-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
 if(grepl(control$regex_pars,'PI'))#
 {#
	 tmp	<- mc$pars$PI#
	 colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
	 pars	<- cbind(pars, tmp)#
 }#
#
  #	traces for parameters#
  if(control$pdf.plot.all.parameters)#
  {#
	  cat('\nPlotting traces for all parameters...')#
	  p		<- mcmc_trace(pars, pars=colnames(pars), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_marginaltraces.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars))#
	  print(p)#
	  dev.off()#
  }#
#
  #	traces for log likelihood and log posterior#
  if(1)#
  {#
	  pars2				<- as.matrix(subset(mc$it.info, BLOCK=='PI', select=c(LOG_LKL, LOG_PRIOR)))#
	  pars2[,2]			<- pars2[,1]+pars2[,2] #
	  colnames(pars2)	<- c('log likelihood','log posterior')	  	    #
	  cat('\nPlotting log likelihood and log posterior...')#
	  p		<- mcmc_trace(pars2, pars=colnames(pars2), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_loglklpotrace.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars2)*2)#
	  print(p)#
	  dev.off()	  #
	  p				<- mcmc_hist(pars2, pars=colnames(pars2), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_loglklpohist.pdf'), w=10, h=control$pdf.height.per.par*ncol(pars2))#
	  print(p)#
	  dev.off()	  #
  }#
#
  #	acceptance rate per MCMC update ID#
  cat('\nPlotting acceptance rates...')#
  da	<- subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, list(ACC_RATE=mean(ACCEPT)), by='PAR_ID']#
  setnames(da, 'PAR_ID', 'UPDATE_ID')#
  tmp	<- mc$dl[, list(N_TRM_CAT_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
  da	<- merge(da, tmp, by='UPDATE_ID')#
  ggplot(da, aes(x=N_TRM_CAT_PAIRS, y=ACC_RATE)) +#
		  geom_point() +#
		  theme_bw() +#
		  scale_y_continuous(label=scales::percent) +#
		  labs(	x='\nNumber of transmission pair categories updated per sampling category',#
				y='Acceptance rate\n')#
  ggsave(file=paste0(control$outfile.base,'_acceptance_per_updateID.pdf'), w=6, h=6)#
  cat('\nAverage acceptance rate= ',subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, round(mean(ACCEPT), d=3)])#
  cat('\nUpdate IDs with lowest acceptance rates')#
  print( da[order(ACC_RATE)[1:10],] )#
#
  # remove burn-in#
  cat('\nRemoving burnin in set to ', 100*control$burnin.p,'% of chain, total iterations=',burnin.n)#
  tmp	<- seq.int(burnin.n+1L,nrow(mc$pars$S))#
  pars	<- pars[tmp,,drop=FALSE]#
#
  # effective sampling sizes#
  cat('\nCalculating effective sample size for all parameters...')#
  tmp	<- mcmc(pars)#
  ans	<- data.table(ID= seq_len(ncol(pars)), VAR= colnames(pars), NEFF=as.numeric(effectiveSize(tmp)))#
  set(ans, NULL, 'ID', ans[, factor(ID, labels=VAR)])#
  if(control$pdf.plot.all.parameters)#
  {#
	  ggplot(ans, aes(x=NEFF, y=ID)) +#
			  geom_point() +#
			  theme_bw() +#
			  labs(x='\neffective sample size', y='')#
	  ggsave(file=paste0(control$outfile.base,'_neff.pdf'), w=6, h=control$pdf.height.per.par*ncol(pars)*0.15, limitsize=FALSE)#
  }#
#
  # summarise mean, sd, quantiles#
  cat('\nCalculating posterior summaries for all parameters...')#
  tmp	<- apply(pars, 2, function(x) quantile(x, p=c((1-control$credibility.interval)/2, 0.5, control$credibility.interval+(1-control$credibility.interval)/2)))#
  tmp	<- data.table(	VAR= colnames(pars),#
		  				MEAN= apply(pars, 2, mean),#
						SD= apply(pars, 2, sd),#
		  				MEDIAN=tmp[2,],#
						CI_L=tmp[1,],#
						CI_U=tmp[3,])#
  ans	<- merge(tmp, ans, by='VAR')#
  cat('\nParameters with lowest effective samples')#
  print( ans[order(NEFF)[1:10],] )#
#
  # write to file#
  cat('\nWriting summary file to',paste0(control$outfile.base,'_summary.csv'))#
  setkey(ans, ID)#
  write.csv(ans, file=paste0(control$outfile.base,'_summary.csv'))#
#
  # plots for worst case parameters#
  if(control$pdf.plot.n.worst.case.parameters>0)#
  {#
	  worst.pars	<- pars[, ans[order(NEFF)[1:control$pdf.plot.n.worst.case.parameters], VAR]]#
	  #	traces#
	  cat('\nPlotting traces for worst parameters...')#
	  p				<- mcmc_trace(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=1))#
	  pdf(file=paste0(control$outfile.base,'_worst_traces.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
#
	  #	histograms#
	  cat('\nPlotting marginal posterior densities for worst parameters...')#
	  p				<- mcmc_hist(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_worst_marginalposteriors.pdf'), w=10, h=control$pdf.height.per.par*ncol(worst.pars)/4)#
	  print(p)#
	  dev.off()#
#
	  #	autocorrelations#
	  cat('\nPlotting autocorrelations for worst parameters...')#
	  p				<- mcmc_acf_bar(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol = 1))#
	  pdf(file=paste0(control$outfile.base,'_worst_acf.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
  }#
}
dprior
infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"#
	infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	for(predict.with.infcounts in c(0,1))#
		for(predict.inflation in c(10,20,30))#
		{#
			RakaiFull.phylogeography.190327.predict.areaflows(	infile.inference.data=infile.inference.data, #
																infile.inference.mcmc=infile.inference.mcmc, #
																infile.subdistricts=infile.subdistricts, #
																predict.with.infcounts=predict.with.infcounts, #
																predict.inflation=predict.inflation)#
			gc()#
		}
predict.with.infcounts<- 1; predict.inflation<- 10
outfile.base						<- gsub('.rda$','',infile.inference.mcmc)#
	tmp									<- gsub('.*_opt([0-9]+).*','\\1',outfile.base)#
	#tmp									<- "112401"#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- as.integer(substr(tmp,1,1))#
	opt$adjust.participation.bias		<- as.integer(substr(tmp,2,2))#
	opt$migration.def.code				<- substr(tmp,3,4)#
	opt$set.missing.migloc.to.inland	<- as.integer(substr(tmp,5,5))#
	opt$set.missing.migloc.to.fishing	<- as.integer(substr(tmp,6,6))#
	opt$predict.with.infcounts			<- predict.with.infcounts#
	opt$predict.inflation				<- predict.inflation#
	cat('\ninfile.inference=',infile.inference.data)#
	cat('\ninfile.inference.mcmc=',infile.inference.mcmc)#
	cat('\ninfile.subdistricts=',infile.subdistricts)#
	cat('\nopt=',unlist(opt))			#
	##
	#	prepare data on observed transmission flows#
	##
	load(infile.inference.data)#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}	#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))	#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )	#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	calculate observed number of transmissions#
	dobsRCCS	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobsRCCS, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobsRCCS[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobsRCCS))]#
	##
	# 	prepare data on fishing / inland areas#
	#		#
	darea	<- desm[, list(	ELIGIBLE=sum(PART_EVER+PART_NEVER),#
							HIV_1516_YES=sum(HIV_1516_YES)#
							), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])#
	load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	rasdata	<- melt(rasdata, id.vars='AREA')#
	rasdata	<- rasdata[, list(EST=round(sum(value),d=0)), by=c('AREA','variable')]#
	set(rasdata, NULL, 'AREA', rasdata[, tolower(AREA)])#
	rasdata[, SEX:= gsub('([A-Z]+)_([A-Z])','\\2',variable)]#
	rasdata[, variable:= gsub('([A-Z]+)_([A-Z])','\\1',variable)]#
	rasdata	<- dcast.data.table(rasdata, AREA+SEX~variable, value.var='EST')#
	darea	<- merge(rasdata, darea, by=c('AREA','SEX'))#
	dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		dprior[, P:= pmin(1, P_HIV)]		#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		dprior[, P:= pmin(1, P_POP)]#
	}	#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	dprior	<- subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))#
	##
	#	make csv table for supplement#
	if(0)#
	{#
		df	<- unique(subset(dsubdis, select=c(AREA, SUBDISTRICT, SEX, COMM_NUM_A, COMM_ELIGIBLE, MAP_POPCOUNT)))	#
		df	<- df[, list(MAP_POPCOUNT=round(MAP_POPCOUNT[1]), RCCS_ELIGIBLE=sum(COMM_ELIGIBLE), RCCS_ELIGIBLE_P=sum(COMM_ELIGIBLE)/MAP_POPCOUNT[1], N_COMM=length(unique(COMM_NUM_A))), by=c('AREA','SUBDISTRICT','SEX')]#
		setkey(df, AREA, SUBDISTRICT, SEX )#
		df[, RCCS_LABEL:= paste0(RCCS_ELIGIBLE,' (',round(RCCS_ELIGIBLE_P*100,d=1),'%)')]#
		write.csv( subset(df, select=c(AREA, SUBDISTRICT, SEX, MAP_POPCOUNT, N_COMM, RCCS_LABEL)), row.names=FALSE, file=gsub('\\.rda','_table.csv',infile.subdistricts))#
	}#
	#	flows that we expect:#
	if(0)#
	{#
		s		<- c(0.2363956, 0.2631666, 0.3919308, 0.5427133)#
		s		<- c(0.16, 0.18, 1, 1)#
		pi		<- c(0.243,0.029,0.039,0.231,0.184,0.006,0.039,0.127)#
		pi		<- pi/sum(pi)#
		pistar	<- c( 	pi[1]/s[4]/s[3],  pi[2]/s[4]/s[1],  pi[3]/s[2]/s[3], pi[4]/s[2]/s[1],#
						pi[5]/s[3]/s[4],  pi[6]/s[3]/s[2],  pi[7]/s[1]/s[4], pi[8]/s[1]/s[2])#
		pistar <- pistar/sum(pistar)#
		c( (pistar[1]+pistar[5]), (pistar[2]+pistar[6]), (pistar[3]+pistar[7]), (pistar[4]+pistar[8]) )#
		(pistar[3]+pistar[7]) / (pistar[2]+pistar[6]) #
		# 'Fish:M','Fish:F',#
	}#
	##
	#	aggregate MCMC samples to areas #
	#	#
	daggregateTo	<- subset(dobsRCCS, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY))]#
	daggregateTo[, REC_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$REC_TRM_CATEGORY))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)		#
	control	<- list(	burnin.p=0.05, #
						thin=NA_integer_, #
						regex_pars='*')#
	mca		<- source.attribution.mcmc.aggregateToTarget(infile.inference.mcmc, daggregateTo, control=control)#
	mca		<- subset(mca, !grepl('external',TR_TARGETCAT))#
	setnames(mca, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs	<- unique(subset(mca, select=c(TR_TRM_CAT, REC_TRM_CAT)))#
	setkey(dobs, TR_TRM_CAT, REC_TRM_CAT)#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]	#
	mca		<- merge(dobs, mca, by=c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs[, TR_SAMPLING_CATEGORY:= TR_TRM_CAT]#
	dobs[, REC_SAMPLING_CATEGORY:= REC_TRM_CAT]#
	##
	#	run MCMC#
	##
	set.seed(42)#
	pp.n			<- 1e4#
	pp.burnin		<- 0.9#
	pp.sweeps		<- 1e2#
	mc				<- list()#
	mc[['pars']]	<- list()#
	mc$pars$Z_RCCS	<- matrix(NA, nrow=pp.n, ncol=nrow(dobs))#
	mc[['pp']]		<- vector('list',pp.n)
i<- 1
dobs[, TRM_OBS:=NULL]#
		tmp					<- subset(mca, VARIABLE=='Z' & SAMPLE==sample(max(mca$SAMPLE), 1))#
		setnames(tmp, 'VALUE', 'TRM_OBS')#
		tmp					<- subset(tmp, select=c(TRM_CAT_PAIR_ID, TRM_OBS))#
		dobs				<- merge(dobs, tmp, by='TRM_CAT_PAIR_ID')#
		cat('\nIteration', i,'\nSetting Z among RCCS communities to', dobs$TRM_OBS)#
		mc$pars$Z_RCCS[i,]	<- dobs$TRM_OBS#
		##
		#	run MCMC and return#
		##
		control			<- list( mcmc.n=9*pp.sweeps, verbose=0 )
dobs
dprior
dmode <- function(x) {#
    den <- density(x, kernel=c("gaussian"))#
    (den$x[den$y==max(den$y)])#
  }#
  ##
  # basic checks#
  ##
  if(!all(dobs$TR_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for TR_SAMPLING_CATEGORY')#
  if(!all(dobs$REC_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for REC_SAMPLING_CATEGORY')#
#
  ptm	<- Sys.time()#
  if('seed'%in%names(control))#
  {#
	  cat('\nSetting seed to',control$seed)#
	  set.seed(control$seed)#
  }#
#
  ##
  # set up mcmc#
  ##
  mc				<- list()#
  #	determine if the sampling probabilities are <1.#
  # If they are NOT, Z will be the same as TRM_OBS, and the algorithm only updates PI#
  mc$with.sampling	<- dprior[, list(ALL_ONE=all(P==1)), by='SAMPLING_CATEGORY'][, !all(ALL_ONE)]#
  mc$time			<- NA_real_#
  # construct look-up table so we know which transmission pair categories need to be updated#
  # at every MCMC iteration#
  tmp				<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_SAMPLING_CATEGORY, REC_SAMPLING_CATEGORY))#
  tmp				<- melt(tmp, id.vars='TRM_CAT_PAIR_ID', value.name='SAMPLING_CATEGORY', variable.name='WHO')#
  #	make data.table with unique sampling categories#
  mc$dlu			<- unique(subset(tmp, select=c(WHO, SAMPLING_CATEGORY)))#
  mc$dlu[, UPDATE_ID:= seq_len(nrow(mc$dlu))]#
  setkey(mc$dlu, UPDATE_ID)#
  # make data.table that maps UPDATE_IDs to TRM_CAT_PAIR_IDs#
  mc$dl				<- merge(mc$dlu, tmp, by=c('WHO','SAMPLING_CATEGORY'))#
  setkey(mc$dl, UPDATE_ID)#
  #	every transmission category pair needs to be updated at least one as we sweep through the sampling categories#
  # I don t think this is guaranteed, hence the check#
  if( !all(dobs$TRM_CAT_PAIR_ID %in% sort(unique(mc$dl$TRM_CAT_PAIR_ID))) )#
	  stop('Fatal error. Contact the package maintainer with your input data.')#
  # make data.table that maps TRM_CAT_PAIR_IDs to transmitter UPDATE_IDs and recipient UPDATE_IDs#
  mc$dlt			<- dcast.data.table(mc$dl, TRM_CAT_PAIR_ID~WHO, value.var='UPDATE_ID')#
  setnames(mc$dlt, c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY'), c('TR_UPDATE_ID','REC_UPDATE_ID'))#
  mc$dlt			<- merge(mc$dlt,subset(dobs,select=c('TRM_CAT_PAIR_ID','TRM_OBS')),by='TRM_CAT_PAIR_ID')#
  setkey(mc$dlt,TRM_CAT_PAIR_ID)
update.info	<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
	  update.info[[i]]	<- mc$dl[UPDATE_ID==i,TRM_CAT_PAIR_ID]#
  }#
  # make indexed prior samples for speed#
  setkey(dprior,SAMPLING_CATEGORY)#
  dprior2		<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
    tmp				<- mc$dlu[UPDATE_ID==i,SAMPLING_CATEGORY]#
    dprior2[[i]]<-dprior[J(tmp),nomatch=0L]#
  }
dmode
dprior
if(dprior[, max(SAMPLE)]>10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=dmode(P)),by=SAMPLING_CATEGORY]  #
  }#
  if(dprior[, max(SAMPLE)]<=10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=median(P)),by=SAMPLING_CATEGORY]#
  }#
  dobs2   <- subset(dobs,select = c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY','TRM_CAT_PAIR_ID'))#
  setnames(dprior3,colnames(dprior3),paste0('TR_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='TR_SAMPLING_CATEGORY')#
  setnames(dprior3,colnames(dprior3),gsub('TR_','REC_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='REC_SAMPLING_CATEGORY')#
  dobs2[,EST_SAMPLING_RATE:=TR_EST_SAMPLING_RATE * REC_EST_SAMPLING_RATE]
mc$nprior			<- max(dprior$SAMPLE)#
  mc$sweep			<- nrow(mc$dlu)+1L#
  mc$nsweep			<- ceiling( control$mcmc.n/mc$sweep )#
  mc$n				<- mc$nsweep*mc$sweep#
  mc$pars			<- list()#
  mc$pars$LAMBDA	<- matrix(NA_real_, ncol=nrow(dobs), nrow=1)		#prior for proportions#
  mc$pars$XI		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # prior for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$XI_LP		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # log prior density for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$S			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # prior probability of sampling transmission pair categories#
  mc$pars$S_LP		<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # log prior density of sampling transmission pair categories#
  mc$pars$Z			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) #augmented data#
  mc$pars$NU		<- NA_real_															#prior for N#
  mc$pars$N			<- matrix(NA_integer_, ncol=1, nrow=mc$nsweep+1L)							#total number of counts on augmented data#
  mc$pars$PI		<- matrix(NA_real_, ncol=nrow(dobs), nrow=mc$nsweep+1L)	#proportions#
  mc$it.info		<- data.table(	IT= seq.int(0,mc$n),#
									PAR_ID= rep(NA_integer_, mc$n+1L),#
									BLOCK= rep(NA_character_, mc$n+1L),#
									MHRATIO= rep(NA_real_, mc$n+1L),#
									ACCEPT=rep(NA_integer_, mc$n+1L),#
									LOG_LKL=rep(NA_real_, mc$n+1L),#
									LOG_PRIOR=rep(NA_real_, mc$n+1L))#
#
  if(1)#
  {#
	  cat('\nNumber of parameters:\t', ncol(mc$pars$PI)+ncol(mc$pars$N)+ncol(mc$pars$Z)+ncol(mc$pars$S)+ncol(mc$pars$XI) )#
	  cat('\nDimension of PI:\t', ncol(mc$pars$PI))#
	  cat('\nSweep length:\t', mc$sweep)#
	  cat('\nNumber of sweeps:\t', mc$nsweep)#
	  cat('\nNumber of iterations:\t', mc$n)#
	  tmp				<- mc$dl[, list(N_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
	  cat('\nNumber of transmission pair categories updated per iteration, and their frequencies:\n')#
	  print(table(tmp$N_PAIRS))#
  }#
  ##
  # initialise MCMC#
  ##
  mc$curr.it			<- 1L#
  set(mc$it.info, mc$curr.it, 'BLOCK', 'INIT')#
  set(mc$it.info, mc$curr.it, 'PAR_ID', 0L)#
  set(mc$it.info, mc$curr.it, 'MHRATIO', 1)#
  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
  #	prior lambda: use the Berger objective prior with minimal loss compared to marginal Beta reference prior#
  #	(https://projecteuclid.org/euclid.ba/1422556416)#
  mc$pars$LAMBDA[1,]	<- 0.8/nrow(dobs)#
  # prior for sampling in transmitter categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='TR_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in in recipient categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='REC_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in transmission pair categories#
  mc$pars$S[1,]			<- mc$pars$XI[1, mc$dlt$TR_UPDATE_ID] * mc$pars$XI[1, mc$dlt$REC_UPDATE_ID]#
  mc$pars$S_LP[1,]		<- mc$pars$XI_LP[1, mc$dlt$TR_UPDATE_ID] + mc$pars$XI_LP[1, mc$dlt$REC_UPDATE_ID]#
  #	augmented data: proposal draw under sampling probability#
  mc$pars$Z[1,]			<- dobs$TRM_OBS + rnbinom(nrow(dobs),dobs$TRM_OBS,mc$pars$S[1,])#
  #	prior nu: set Poisson rate to the expected augmented counts, under average sampling probability#
  mc$pars$NU			<- sum(dobs$TRM_OBS) / mean(dobs2$EST_SAMPLING_RATE)#
  #	total count: that s just the sum of Z#
  mc$pars$N[1,]			<- sum(mc$pars$Z[1,])#
  #	proportions: draw from full conditional#
  mc$pars$PI[1,]		<- rdirichlet(1, mc$pars$Z[1,] + mc$pars$LAMBDA[1,])#
  #	store log likelihood#
  tmp	<- sum( dbinom(dobs$TRM_OBS, size=mc$pars$Z[1,], prob=mc$pars$S[1,], log=TRUE) ) +#
    dmultinom(mc$pars$Z[1,], size=mc$pars$N[1,], prob=mc$pars$PI[1,], log=TRUE)#
  set(mc$it.info, 1L, 'LOG_LKL', tmp)#
  # 	store log prior#
  tmp	<- dpois(mc$pars$N[1,], lambda=mc$pars$NU, log=TRUE) +#
    		lddirichlet_vector(mc$pars$PI[1,], nu=mc$pars$LAMBDA[1,]) +#
    		sum(mc$pars$S_LP[1,])#
  set(mc$it.info, 1L, 'LOG_PRIOR', tmp)
XI.curr	<- mc$pars$XI[1,]#
  XI_LP.curr<- mc$pars$XI_LP[1,]#
  S.curr	<- mc$pars$S[1,]#
  S_LP.curr	<- mc$pars$S_LP[1,]#
  PI.curr	<- mc$pars$PI[1,]#
  N.curr	<- mc$pars$N[1,]#
  Z.curr	<- mc$pars$Z[1,]#
#
  # run mcmc#
  options(warn=0)#
  for(i in 1L:mc$n)#
  {#
    mc$curr.it		<- i#
    # determine source-recipient combination that will be updated in this iteration#
    update.count	<- (i-1L) %% mc$sweep + 1L#
    update.round 	<- (i-1L) %/% mc$sweep + 1L#
	# update in one go S, Z, N for the ith XI#
    if(mc$with.sampling & update.count<mc$sweep)#
    {#
	  # update.info	<- subset(mc$dl, UPDATE_ID==update.count)	# recompute for each sweep + the category and the pair id#
      update.cat	<- mc$dlu$SAMPLING_CATEGORY[update.count]#
      update.pairs	<- update.info[[update.count]]#
#
      # propose single XI#
	  XI.prop		<- XI.curr#
	  XI_LP.prop	<- XI_LP.curr#
	  tmp			<- dprior2[[update.count]][sample(mc$nprior,1),]#
	  if(tmp$SAMPLING_CATEGORY[1]!=update.cat)#
		  stop('\nFatal error in dprior2.')#
	  XI.prop[ update.count ]	<- tmp$P#
	  XI_LP.prop[ update.count ]<- tmp$LP#
	  # propose all S that involve the one XI from above#
	  S.prop						<- S.curr#
	  S_LP.prop						<- S_LP.curr#
	  S.prop[update.pairs]			<- XI.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] * XI.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  S_LP.prop[update.pairs]		<- XI_LP.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] + XI_LP.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  # propose all Z that involve a new S#
	  Z.prop						<- Z.curr#
	  Z.prop[update.pairs]			<- mc$dlt$TRM_OBS[update.pairs] + rnbinom(length(update.pairs), mc$dlt$TRM_OBS[update.pairs], S.prop[update.pairs])#
	  # propose total of Z#
	  N.prop						<- sum(Z.prop)#
	  #	calculate MH ratio#
	  log.prop.ratio	<- sum(dnbinom(Z.curr[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.curr[update.pairs], log=TRUE)) -#
						   sum(dnbinom(Z.prop[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.prop[update.pairs], log=TRUE))#
	  log.fc			<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.curr[update.pairs], prob=S.curr[update.pairs], log=TRUE)) +#
						   dmultinom(Z.curr, prob=PI.curr, log=TRUE) +#
						   dpois(N.curr, lambda=mc$pars$NU, log=TRUE)#
	  log.fc.prop		<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.prop[update.pairs], prob=S.prop[update.pairs], log=TRUE)) +#
			  			   dmultinom(Z.prop, prob=PI.curr, log=TRUE) +#
			  			   dpois(N.prop, lambda=mc$pars$NU, log=TRUE)#
	  log.mh.ratio		<- log.fc.prop - log.fc + log.prop.ratio#
	  mh.ratio			<- min(1,exp(log.mh.ratio))#
	  #	update#
	  mc$curr.it		<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'S-Z-N')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', update.count)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', mh.ratio)#
	  accept 			<- as.integer(runif(1) < mh.ratio)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', accept)#
#
	  if(control$verbose & accept)#
	  {#
		  cat('\nit ',mc$curr.it,' ACCEPT S-Z-N block ',update.count)#
	  }#
	  if(accept)#
	  {#
		  XI.curr	<- XI.prop#
		  XI_LP.curr<- XI_LP.prop#
		  S.curr	<- S.prop#
		  S_LP.curr	<- S_LP.prop#
		  Z.curr	<- Z.prop#
		  N.curr	<- N.prop#
	  }#
    }#
#
    # update PI#
    if(!mc$with.sampling | update.count==mc$sweep)#
    {#
      #	propose#
      PI.prop		<- rdirichlet(1L, Z.curr + mc$pars$LAMBDA[1,])#
      #	this is the full conditional of PI given S, N, Z#
      #	always accept#
      #	update#
	  mc$curr.it	<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'PI')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', NA_integer_)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', 1L)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
      PI.curr		<- PI.prop#
#
	  # at the end of sweep, record current parameters#
      mc$pars$XI[update.round+1L,]		<- XI.curr#
	  mc$pars$XI_LP[update.round+1L,]	<- XI_LP.curr#
      mc$pars$S[update.round+1L,]		<- S.curr#
	  mc$pars$S_LP[update.round+1L,]	<- S_LP.curr#
      mc$pars$Z[update.round+1L,]		<- Z.curr#
      mc$pars$N[update.round+1L,]		<- N.curr#
      mc$pars$PI[update.round+1L,]		<- PI.curr#
    }#
#
	# 	record log likelihood#
	tmp	<- sum(dbinom(dobs$TRM_OBS, size=Z.curr, prob=S.curr, log=TRUE) ) +#
	    		dmultinom(Z.curr, size=N.curr, prob=PI.curr, log=TRUE)#
	set(mc$it.info, mc$curr.it, 'LOG_LKL', tmp)#
	# 	record log prior#
	tmp	<- dpois(N.curr, lambda=mc$pars$NU, log=TRUE) +#
	  			lddirichlet_vector(PI.curr, nu=mc$pars$LAMBDA[1,]) +#
			  	sum(S_LP.curr)#
	set(mc$it.info, mc$curr.it, 'LOG_PRIOR', tmp)#
	##
	if(update.count==mc$sweep & update.round %% 100 == 0){#
		cat('\nSweeps done:\t',update.round)#
	}#
  }#
#
  mc$time	<- Sys.time()-ptm
lddirichlet_vector	<- function(x, nu){#
	ans	<- sum((nu - 1) * log(x)) + sum(lgamma(nu)) - lgamma(sum(nu))#
	stopifnot(is.finite(ans))#
	ans#
}#
#
#' @title Source attribution while adjusting for sampling bias#
#' @export#
#' @import data.table#
#' @importFrom gtools rdirichlet#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param dobs Data.table of observed number of transmission events for each transmission pair category.#
#' @param dprior Data.table of draws from the prior distribution of sampling probabilities.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"seed"}{Random number seed, for reproducibility.}#
#'  \item{"mcmc.n"}{Guide on the number of MCMC iterations. The actual number of iterations will be slightly larger, and a multiple of the number of iterations needed to complete one MCMC sweep through all free parameters.}#
#'  \item{"verbose"}{Flag to switch on/off verbose output.}#
#'  \item{"outfile"}{Full path name to which the MCMC output is saved to in RDA format, in an object called \code{mc}.}#
#' }#
#' @return NULL. MCMC output is written to an RDA file.#
source.attribution.mcmc	<- function(dobs, dprior, control=list(seed=42, mcmc.n=1e3, verbose=1, outfile='SAMCMCv190327.rda')){#
  #library(data.table); library(gtools)#
#
  dmode <- function(x) {#
    den <- density(x, kernel=c("gaussian"))#
    (den$x[den$y==max(den$y)])#
  }#
  ##
  # basic checks#
  ##
  if(!all(dobs$TR_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for TR_SAMPLING_CATEGORY')#
  if(!all(dobs$REC_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for REC_SAMPLING_CATEGORY')#
#
  ptm	<- Sys.time()#
  if('seed'%in%names(control))#
  {#
	  cat('\nSetting seed to',control$seed)#
	  set.seed(control$seed)#
  }#
#
  ##
  # set up mcmc#
  ##
  mc				<- list()#
  #	determine if the sampling probabilities are <1.#
  # If they are NOT, Z will be the same as TRM_OBS, and the algorithm only updates PI#
  mc$with.sampling	<- dprior[, list(ALL_ONE=all(P==1)), by='SAMPLING_CATEGORY'][, !all(ALL_ONE)]#
  mc$time			<- NA_real_#
  # construct look-up table so we know which transmission pair categories need to be updated#
  # at every MCMC iteration#
  tmp				<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_SAMPLING_CATEGORY, REC_SAMPLING_CATEGORY))#
  tmp				<- melt(tmp, id.vars='TRM_CAT_PAIR_ID', value.name='SAMPLING_CATEGORY', variable.name='WHO')#
  #	make data.table with unique sampling categories#
  mc$dlu			<- unique(subset(tmp, select=c(WHO, SAMPLING_CATEGORY)))#
  mc$dlu[, UPDATE_ID:= seq_len(nrow(mc$dlu))]#
  setkey(mc$dlu, UPDATE_ID)#
  # make data.table that maps UPDATE_IDs to TRM_CAT_PAIR_IDs#
  mc$dl				<- merge(mc$dlu, tmp, by=c('WHO','SAMPLING_CATEGORY'))#
  setkey(mc$dl, UPDATE_ID)#
  #	every transmission category pair needs to be updated at least one as we sweep through the sampling categories#
  # I don t think this is guaranteed, hence the check#
  if( !all(dobs$TRM_CAT_PAIR_ID %in% sort(unique(mc$dl$TRM_CAT_PAIR_ID))) )#
	  stop('Fatal error. Contact the package maintainer with your input data.')#
  # make data.table that maps TRM_CAT_PAIR_IDs to transmitter UPDATE_IDs and recipient UPDATE_IDs#
  mc$dlt			<- dcast.data.table(mc$dl, TRM_CAT_PAIR_ID~WHO, value.var='UPDATE_ID')#
  setnames(mc$dlt, c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY'), c('TR_UPDATE_ID','REC_UPDATE_ID'))#
  mc$dlt			<- merge(mc$dlt,subset(dobs,select=c('TRM_CAT_PAIR_ID','TRM_OBS')),by='TRM_CAT_PAIR_ID')#
  setkey(mc$dlt,TRM_CAT_PAIR_ID)#
#
  # make indexed lookup table for speed#
  update.info	<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
	  update.info[[i]]	<- mc$dl[UPDATE_ID==i,TRM_CAT_PAIR_ID]#
  }#
  # make indexed prior samples for speed#
  setkey(dprior,SAMPLING_CATEGORY)#
  dprior2		<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
    tmp				<- mc$dlu[UPDATE_ID==i,SAMPLING_CATEGORY]#
    dprior2[[i]]	<- dprior[J(tmp),nomatch=0L]#
  }#
  if(dprior[, max(SAMPLE)]>10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=dmode(P)),by=SAMPLING_CATEGORY]  #
  }#
  if(dprior[, max(SAMPLE)]<=10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=median(P)),by=SAMPLING_CATEGORY]#
  }#
  dobs2   <- subset(dobs,select = c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY','TRM_CAT_PAIR_ID'))#
  setnames(dprior3,colnames(dprior3),paste0('TR_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='TR_SAMPLING_CATEGORY')#
  setnames(dprior3,colnames(dprior3),gsub('TR_','REC_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='REC_SAMPLING_CATEGORY')#
  dobs2[,EST_SAMPLING_RATE:=TR_EST_SAMPLING_RATE * REC_EST_SAMPLING_RATE]#
#
  mc$nprior			<- max(dprior$SAMPLE)#
  mc$sweep			<- nrow(mc$dlu)+1L#
  mc$nsweep			<- ceiling( control$mcmc.n/mc$sweep )#
  mc$n				<- mc$nsweep*mc$sweep#
  mc$pars			<- list()#
  mc$pars$LAMBDA	<- matrix(NA_real_, ncol=nrow(dobs), nrow=1)		#prior for proportions#
  mc$pars$XI		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # prior for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$XI_LP		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # log prior density for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$S			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # prior probability of sampling transmission pair categories#
  mc$pars$S_LP		<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # log prior density of sampling transmission pair categories#
  mc$pars$Z			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) #augmented data#
  mc$pars$NU		<- NA_real_															#prior for N#
  mc$pars$N			<- matrix(NA_integer_, ncol=1, nrow=mc$nsweep+1L)							#total number of counts on augmented data#
  mc$pars$PI		<- matrix(NA_real_, ncol=nrow(dobs), nrow=mc$nsweep+1L)	#proportions#
  mc$it.info		<- data.table(	IT= seq.int(0,mc$n),#
									PAR_ID= rep(NA_integer_, mc$n+1L),#
									BLOCK= rep(NA_character_, mc$n+1L),#
									MHRATIO= rep(NA_real_, mc$n+1L),#
									ACCEPT=rep(NA_integer_, mc$n+1L),#
									LOG_LKL=rep(NA_real_, mc$n+1L),#
									LOG_PRIOR=rep(NA_real_, mc$n+1L))#
#
  if(1)#
  {#
	  cat('\nNumber of parameters:\t', ncol(mc$pars$PI)+ncol(mc$pars$N)+ncol(mc$pars$Z)+ncol(mc$pars$S)+ncol(mc$pars$XI) )#
	  cat('\nDimension of PI:\t', ncol(mc$pars$PI))#
	  cat('\nSweep length:\t', mc$sweep)#
	  cat('\nNumber of sweeps:\t', mc$nsweep)#
	  cat('\nNumber of iterations:\t', mc$n)#
	  tmp				<- mc$dl[, list(N_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
	  cat('\nNumber of transmission pair categories updated per iteration, and their frequencies:\n')#
	  print(table(tmp$N_PAIRS))#
  }#
  ##
  # initialise MCMC#
  ##
  mc$curr.it			<- 1L#
  set(mc$it.info, mc$curr.it, 'BLOCK', 'INIT')#
  set(mc$it.info, mc$curr.it, 'PAR_ID', 0L)#
  set(mc$it.info, mc$curr.it, 'MHRATIO', 1)#
  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
  #	prior lambda: use the Berger objective prior with minimal loss compared to marginal Beta reference prior#
  #	(https://projecteuclid.org/euclid.ba/1422556416)#
  mc$pars$LAMBDA[1,]	<- 0.8/nrow(dobs)#
  # prior for sampling in transmitter categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='TR_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in in recipient categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='REC_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in transmission pair categories#
  mc$pars$S[1,]			<- mc$pars$XI[1, mc$dlt$TR_UPDATE_ID] * mc$pars$XI[1, mc$dlt$REC_UPDATE_ID]#
  mc$pars$S_LP[1,]		<- mc$pars$XI_LP[1, mc$dlt$TR_UPDATE_ID] + mc$pars$XI_LP[1, mc$dlt$REC_UPDATE_ID]#
  #	augmented data: proposal draw under sampling probability#
  mc$pars$Z[1,]			<- dobs$TRM_OBS + rnbinom(nrow(dobs),dobs$TRM_OBS,mc$pars$S[1,])#
  #	prior nu: set Poisson rate to the expected augmented counts, under average sampling probability#
  mc$pars$NU			<- sum(dobs$TRM_OBS) / mean(dobs2$EST_SAMPLING_RATE)#
  #	total count: that s just the sum of Z#
  mc$pars$N[1,]			<- sum(mc$pars$Z[1,])#
  #	proportions: draw from full conditional#
  mc$pars$PI[1,]		<- rdirichlet(1, mc$pars$Z[1,] + mc$pars$LAMBDA[1,])#
  #	store log likelihood#
  tmp	<- sum( dbinom(dobs$TRM_OBS, size=mc$pars$Z[1,], prob=mc$pars$S[1,], log=TRUE) ) +#
    dmultinom(mc$pars$Z[1,], size=mc$pars$N[1,], prob=mc$pars$PI[1,], log=TRUE)#
  set(mc$it.info, 1L, 'LOG_LKL', tmp)#
  # 	store log prior#
  tmp	<- dpois(mc$pars$N[1,], lambda=mc$pars$NU, log=TRUE) +#
    		lddirichlet_vector(mc$pars$PI[1,], nu=mc$pars$LAMBDA[1,]) +#
    		sum(mc$pars$S_LP[1,])#
  set(mc$it.info, 1L, 'LOG_PRIOR', tmp)#
  # parameter value at the current step#
  XI.curr	<- mc$pars$XI[1,]#
  XI_LP.curr<- mc$pars$XI_LP[1,]#
  S.curr	<- mc$pars$S[1,]#
  S_LP.curr	<- mc$pars$S_LP[1,]#
  PI.curr	<- mc$pars$PI[1,]#
  N.curr	<- mc$pars$N[1,]#
  Z.curr	<- mc$pars$Z[1,]#
#
  # run mcmc#
  options(warn=0)#
  for(i in 1L:mc$n)#
  {#
    mc$curr.it		<- i#
    # determine source-recipient combination that will be updated in this iteration#
    update.count	<- (i-1L) %% mc$sweep + 1L#
    update.round 	<- (i-1L) %/% mc$sweep + 1L#
	# update in one go S, Z, N for the ith XI#
    if(mc$with.sampling & update.count<mc$sweep)#
    {#
	  # update.info	<- subset(mc$dl, UPDATE_ID==update.count)	# recompute for each sweep + the category and the pair id#
      update.cat	<- mc$dlu$SAMPLING_CATEGORY[update.count]#
      update.pairs	<- update.info[[update.count]]#
#
      # propose single XI#
	  XI.prop		<- XI.curr#
	  XI_LP.prop	<- XI_LP.curr#
	  tmp			<- dprior2[[update.count]][sample(mc$nprior,1),]#
	  if(tmp$SAMPLING_CATEGORY[1]!=update.cat)#
		  stop('\nFatal error in dprior2.')#
	  XI.prop[ update.count ]	<- tmp$P#
	  XI_LP.prop[ update.count ]<- tmp$LP#
	  # propose all S that involve the one XI from above#
	  S.prop						<- S.curr#
	  S_LP.prop						<- S_LP.curr#
	  S.prop[update.pairs]			<- XI.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] * XI.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  S_LP.prop[update.pairs]		<- XI_LP.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] + XI_LP.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  # propose all Z that involve a new S#
	  Z.prop						<- Z.curr#
	  Z.prop[update.pairs]			<- mc$dlt$TRM_OBS[update.pairs] + rnbinom(length(update.pairs), mc$dlt$TRM_OBS[update.pairs], S.prop[update.pairs])#
	  # propose total of Z#
	  N.prop						<- sum(Z.prop)#
	  #	calculate MH ratio#
	  log.prop.ratio	<- sum(dnbinom(Z.curr[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.curr[update.pairs], log=TRUE)) -#
						   sum(dnbinom(Z.prop[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.prop[update.pairs], log=TRUE))#
	  log.fc			<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.curr[update.pairs], prob=S.curr[update.pairs], log=TRUE)) +#
						   dmultinom(Z.curr, prob=PI.curr, log=TRUE) +#
						   dpois(N.curr, lambda=mc$pars$NU, log=TRUE)#
	  log.fc.prop		<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.prop[update.pairs], prob=S.prop[update.pairs], log=TRUE)) +#
			  			   dmultinom(Z.prop, prob=PI.curr, log=TRUE) +#
			  			   dpois(N.prop, lambda=mc$pars$NU, log=TRUE)#
	  log.mh.ratio		<- log.fc.prop - log.fc + log.prop.ratio#
	  mh.ratio			<- min(1,exp(log.mh.ratio))#
	  #	update#
	  mc$curr.it		<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'S-Z-N')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', update.count)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', mh.ratio)#
	  accept 			<- as.integer(runif(1) < mh.ratio)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', accept)#
#
	  if(control$verbose & accept)#
	  {#
		  cat('\nit ',mc$curr.it,' ACCEPT S-Z-N block ',update.count)#
	  }#
	  if(accept)#
	  {#
		  XI.curr	<- XI.prop#
		  XI_LP.curr<- XI_LP.prop#
		  S.curr	<- S.prop#
		  S_LP.curr	<- S_LP.prop#
		  Z.curr	<- Z.prop#
		  N.curr	<- N.prop#
	  }#
    }#
#
    # update PI#
    if(!mc$with.sampling | update.count==mc$sweep)#
    {#
      #	propose#
      PI.prop		<- rdirichlet(1L, Z.curr + mc$pars$LAMBDA[1,])#
      #	this is the full conditional of PI given S, N, Z#
      #	always accept#
      #	update#
	  mc$curr.it	<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'PI')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', NA_integer_)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', 1L)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
      PI.curr		<- PI.prop#
#
	  # at the end of sweep, record current parameters#
      mc$pars$XI[update.round+1L,]		<- XI.curr#
	  mc$pars$XI_LP[update.round+1L,]	<- XI_LP.curr#
      mc$pars$S[update.round+1L,]		<- S.curr#
	  mc$pars$S_LP[update.round+1L,]	<- S_LP.curr#
      mc$pars$Z[update.round+1L,]		<- Z.curr#
      mc$pars$N[update.round+1L,]		<- N.curr#
      mc$pars$PI[update.round+1L,]		<- PI.curr#
    }#
#
	# 	record log likelihood#
	tmp	<- sum(dbinom(dobs$TRM_OBS, size=Z.curr, prob=S.curr, log=TRUE) ) +#
	    		dmultinom(Z.curr, size=N.curr, prob=PI.curr, log=TRUE)#
	set(mc$it.info, mc$curr.it, 'LOG_LKL', tmp)#
	# 	record log prior#
	tmp	<- dpois(N.curr, lambda=mc$pars$NU, log=TRUE) +#
	  			lddirichlet_vector(PI.curr, nu=mc$pars$LAMBDA[1,]) +#
			  	sum(S_LP.curr)#
	set(mc$it.info, mc$curr.it, 'LOG_PRIOR', tmp)#
	##
	if(update.count==mc$sweep & update.round %% 100 == 0){#
		cat('\nSweeps done:\t',update.round)#
	}#
  }#
#
  mc$time	<- Sys.time()-ptm#
  if(!'outfile'%in%names(control))#
	  return(mc)#
  save(mc,	file=control$outfile)#
  NULL#
}#
#
#' @title Aggregate MCMC output to target parameters#
#' @export#
#' @import data.table#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param daggregateTo Data.table that maps the categories of transmission pairs used in the MCMC to lower-dimensional categories that are of primary interest.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"thin"}{Thin MCMC output to every nth MCMC iteration.}#
#'  \item{"regex_pars"}{Regular expression to select the parameters that are to be aggregated.}#
#'  \item{"outfile"}{Full file name of the output csv file.}#
#' }#
#' @return NULL. Monte Carlo samples are written to a csv file.#
source.attribution.mcmc.aggregateToTarget	<- function(mcmc.file, daggregateTo, control=list(burnin.p=NA_real_, thin=NA_integer_, regex_pars='*', outfile=gsub('\\.rda','_aggregated.csv',mcmc.file))){#
	#	basic checks#
	if(!'data.table'%in%class(daggregateTo))#
		stop('daggregateTo is not a data.table')#
	if(!all(c('TRM_CAT_PAIR_ID','TR_TARGETCAT','REC_TARGETCAT')%in%colnames(daggregateTo)))#
		stop('daggregateTo does not contain one of the required columns TRM_CAT_PAIR_ID, TR_TARGETCAT, REC_TARGETCAT')#
#
	#	load MCMC output#
	cat('\nLoading MCMC output...')#
	load(mcmc.file)#
#
	#	define internal control variables#
	burnin.p	<- control$burnin.p#
	if(is.na(burnin.p))#
		burnin.p<- 0#
	burnin.n	<- floor(burnin.p*nrow(mc$pars$S))#
	thin		<- control$thin#
	if(is.na(thin))#
		thin	<- 1#
#
	#	collect parameters#
	cat('\nCollecting parameters...')#
	pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
	if(grepl(control$regex_pars,'Z'))#
	{#
		tmp	<- mc$pars$Z#
		colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
	if(grepl(control$regex_pars,'PI'))#
	{#
		tmp	<- mc$pars$PI#
		colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
#
	# remove burn-in#
	if(burnin.n>0)#
	{#
		cat('\nRemoving burnin in set to ', 100*burnin.p,'% of chain, total iterations=',burnin.n)#
		tmp		<- seq.int(burnin.n,nrow(mc$pars$S))#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	# thin#
	if(thin>1)#
	{#
		cat('\nThinning to every', thin,'th iteration')#
		tmp		<- seq.int(1,nrow(pars),thin)#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	cat('\nMaking aggregated MCMC output...')#
	# make data.table in long format#
	pars	<- as.data.table(pars)#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
#
	# aggregate MCMC samples#
	if(!all(sort(unique(pars$TRM_CAT_PAIR_ID))==sort(unique(daggregateTo$TRM_CAT_PAIR_ID))))#
		stop('The transmission count categories in the MCMC output do not match the transmission count categories in the aggregateTo data table.')#
	pars	<- merge(pars, daggregateTo, by='TRM_CAT_PAIR_ID')#
	pars	<- pars[, list(VALUE=sum(value)), by=c('VARIABLE','TR_TARGETCAT','REC_TARGETCAT','SAMPLE')]#
#
	# save or return#
	if(!'outfile'%in%names(control))#
		return(pars)#
	if(grepl('csv$',control$outfile))#
	{#
		cat('\nWriting csv file to',control$outfile)#
		write.csv(pars, row.names=FALSE, file=control$outfile)#
	}#
	if(grepl('rda$',control$outfile))#
	{#
		cat('\nSaving rda file to',control$outfile)#
		save(pars, file=control$outfile)#
	}#
}#
#
#' @title Estimate Flows, Sources, WAIFM, Flow ratios#
#' @export#
#' @import data.table#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param infile Full file name to aggregated MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the derivation of key quantities:#
#' \itemize{#
#'  \item{"quantiles"}{Named list of quantiles. Default: c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)}#
#'  \item{"flowratios"}{Cector of length 3. First element: name of flow ratio. Second element: name of transmission pair category for enumerator of flow ratio. Third element: name of transmission pair category for denominator of flow ratio.}#
#'  \item{"outfile"}{Full file name for output csv file.}#
#' }#
#' @return NULL. A csv file is written to disk.#
source.attribution.aggmcmc.getKeyQuantities<- function(infile, control)#
{#
	cat('\nReading aggregated MCMC output...')#
	pars		<- as.data.table(read.csv(infile, stringsAsFactors=FALSE))#
	pars		<- subset(pars, VARIABLE=='PI')#
	if(any(is.na(pars$VALUE)))#
	{#
		cat('\nRemoving NA output for samples n=', nrow(subset(pars, is.na(VALUE))))#
		pars		<- subset(pars, !is.na(VALUE))#
	}#
	cat('\nComputing flows...')#
	#	calculate flows#
	z		<- pars[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='flows']#
	ans		<- copy(z)#
	gc()#
#
	cat('\nComputing WAIFM...')#
	#	calculate WAIFM#
	z		<- pars[, list(REC_TARGETCAT=REC_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('TR_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='waifm']#
	ans		<- rbind(ans,z)#
	gc()#
#
	cat('\nComputing sources...')#
	#	calculate sources#
	z		<- pars[, list(TR_TARGETCAT=TR_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, REC_TARGETCAT, TR_TARGETCAT )#
	z[, STAT:='sources']#
	ans		<- rbind(ans,z)#
	gc()#
#
	if(length(control$flowratios)>0)#
	{#
		cat('\nComputing flow ratios...')#
		#	calculate transmission flow ratios#
		z		<- copy(pars)#
		z[, FLOW:=paste0(TR_TARGETCAT,' ',REC_TARGETCAT)]#
		z		<- dcast.data.table(z, SAMPLE~FLOW, value.var='VALUE')#
		set(z, NULL, colnames(z)[!colnames(z)%in%c('SAMPLE',unlist(control$flowratios))], NULL)#
		for(ii in seq_along(control$flowratios))#
		{#
			if(!control$flowratios[[ii]][2]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][2],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][2], 0)#
			}#
			if(!control$flowratios[[ii]][3]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][3],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][3], 0)#
			}#
			set(z, NULL, control$flowratios[[ii]][1], z[[ control$flowratios[[ii]][2] ]] /  z[[ control$flowratios[[ii]][3] ]])#
			set(z, NULL, c(control$flowratios[[ii]][2],control$flowratios[[ii]][3]), NULL)#
		}#
		z		<- melt(z, id.vars='SAMPLE', value.name='VALUE', variable.name='FLOWRATIO_CAT')#
		z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('FLOWRATIO_CAT')]#
		z		<- dcast.data.table(z, FLOWRATIO_CAT~P, value.var='Q')#
		z[, LABEL:= paste0(round(M, d=2), '\n[',round(CL,d=2),' - ',round(CU,d=2),']')]#
		z[, LABEL2:= paste0(round(M, d=2), ' (',round(CL,d=2),'-',round(CU,d=2),')')]#
		z[, STAT:='flow_ratio']#
		ans		<- rbind(ans,z, fill=TRUE)#
		gc()#
	}#
#
	cat('\nWriting output to',control$outfile)#
	write.csv(ans, row.names=FALSE,file=control$outfile)#
}#
#' @title MCMC diagnostics for the source attribution algorithm#
#' @export#
#' @import data.table#
#' @import ggplot2#
#' @importFrom bayesplot mcmc_trace mcmc_acf_bar mcmc_hist#
#' @importFrom coda mcmc effectiveSize#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"regex_pars"}{Regular expression to select the parameter names for which diagnostics are computed. The default is all parameters, which is '*'.}#
#'  \item{"credibility.interval"}{Width of the marginal posterior credibility intervals.}#
#'  \item{"pdf.plot.n.worst.case.parameters"}{Integer which specifies the number of parameters with smallest effective sample size that are inspected in detail. If set to 0, worst case analyses are not performed.}#
#'  \item{"pdf.plot.all.parameters"}{Flag which specifies if traces shall be plotted for all parameters. If set to TRUE, very large pdfs may be created.}#
#'  \item{"pdf.height.per.par"}{Most plots show diagnostics with parameters listed on the y-axis. This value controls the plot height in inches for each free parameter.}#
#'  \item{"outfile.base"}{Start of the full file name for all output files.}#
#' }#
#' @return NULL. Diagnostic plots and csv files are written to disk.#
source.attribution.mcmc.diagnostics	<- function(mcmc.file, control=list(burnin.p=0.2, regex_pars='*', credibility.interval=0.95, pdf.plot.n.worst.case.parameters=10, pdf.plot.all.parameters=FALSE, pdf.height.per.par=1.2, outfile.base=gsub('\\.rda','',mcmc.file))){#
  #library(coda); library(data.table); library(bayesplot); library(ggplot2)#
#
  cat('\nLoading MCMC output...')#
  load(mcmc.file)#
#
  burnin.n	<- floor(control$burnin.p*nrow(mc$pars$S))#
#
  cat('\nCollecting parameters...')#
  pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
  if(grepl(control$regex_pars,'S'))#
  {#
	  tmp	<- mc$pars$S#
	  colnames(tmp)	<- paste0('S-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'Z'))#
  {#
	  tmp	<- mc$pars$Z#
	  colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'N'))#
  {#
	  tmp	<- mc$pars$N#
	  colnames(tmp)	<- paste0('N-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
 if(grepl(control$regex_pars,'PI'))#
 {#
	 tmp	<- mc$pars$PI#
	 colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
	 pars	<- cbind(pars, tmp)#
 }#
#
  #	traces for parameters#
  if(control$pdf.plot.all.parameters)#
  {#
	  cat('\nPlotting traces for all parameters...')#
	  p		<- mcmc_trace(pars, pars=colnames(pars), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_marginaltraces.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars))#
	  print(p)#
	  dev.off()#
  }#
#
  #	traces for log likelihood and log posterior#
  if(1)#
  {#
	  pars2				<- as.matrix(subset(mc$it.info, BLOCK=='PI', select=c(LOG_LKL, LOG_PRIOR)))#
	  pars2[,2]			<- pars2[,1]+pars2[,2] #
	  colnames(pars2)	<- c('log likelihood','log posterior')	  	    #
	  cat('\nPlotting log likelihood and log posterior...')#
	  p		<- mcmc_trace(pars2, pars=colnames(pars2), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_loglklpotrace.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars2)*2)#
	  print(p)#
	  dev.off()	  #
	  p				<- mcmc_hist(pars2, pars=colnames(pars2), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_loglklpohist.pdf'), w=10, h=control$pdf.height.per.par*ncol(pars2))#
	  print(p)#
	  dev.off()	  #
  }#
#
  #	acceptance rate per MCMC update ID#
  cat('\nPlotting acceptance rates...')#
  da	<- subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, list(ACC_RATE=mean(ACCEPT)), by='PAR_ID']#
  setnames(da, 'PAR_ID', 'UPDATE_ID')#
  tmp	<- mc$dl[, list(N_TRM_CAT_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
  da	<- merge(da, tmp, by='UPDATE_ID')#
  ggplot(da, aes(x=N_TRM_CAT_PAIRS, y=ACC_RATE)) +#
		  geom_point() +#
		  theme_bw() +#
		  scale_y_continuous(label=scales::percent) +#
		  labs(	x='\nNumber of transmission pair categories updated per sampling category',#
				y='Acceptance rate\n')#
  ggsave(file=paste0(control$outfile.base,'_acceptance_per_updateID.pdf'), w=6, h=6)#
  cat('\nAverage acceptance rate= ',subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, round(mean(ACCEPT), d=3)])#
  cat('\nUpdate IDs with lowest acceptance rates')#
  print( da[order(ACC_RATE)[1:10],] )#
#
  # remove burn-in#
  cat('\nRemoving burnin in set to ', 100*control$burnin.p,'% of chain, total iterations=',burnin.n)#
  tmp	<- seq.int(burnin.n+1L,nrow(mc$pars$S))#
  pars	<- pars[tmp,,drop=FALSE]#
#
  # effective sampling sizes#
  cat('\nCalculating effective sample size for all parameters...')#
  tmp	<- mcmc(pars)#
  ans	<- data.table(ID= seq_len(ncol(pars)), VAR= colnames(pars), NEFF=as.numeric(effectiveSize(tmp)))#
  set(ans, NULL, 'ID', ans[, factor(ID, labels=VAR)])#
  if(control$pdf.plot.all.parameters)#
  {#
	  ggplot(ans, aes(x=NEFF, y=ID)) +#
			  geom_point() +#
			  theme_bw() +#
			  labs(x='\neffective sample size', y='')#
	  ggsave(file=paste0(control$outfile.base,'_neff.pdf'), w=6, h=control$pdf.height.per.par*ncol(pars)*0.15, limitsize=FALSE)#
  }#
#
  # summarise mean, sd, quantiles#
  cat('\nCalculating posterior summaries for all parameters...')#
  tmp	<- apply(pars, 2, function(x) quantile(x, p=c((1-control$credibility.interval)/2, 0.5, control$credibility.interval+(1-control$credibility.interval)/2)))#
  tmp	<- data.table(	VAR= colnames(pars),#
		  				MEAN= apply(pars, 2, mean),#
						SD= apply(pars, 2, sd),#
		  				MEDIAN=tmp[2,],#
						CI_L=tmp[1,],#
						CI_U=tmp[3,])#
  ans	<- merge(tmp, ans, by='VAR')#
  cat('\nParameters with lowest effective samples')#
  print( ans[order(NEFF)[1:10],] )#
#
  # write to file#
  cat('\nWriting summary file to',paste0(control$outfile.base,'_summary.csv'))#
  setkey(ans, ID)#
  write.csv(ans, file=paste0(control$outfile.base,'_summary.csv'))#
#
  # plots for worst case parameters#
  if(control$pdf.plot.n.worst.case.parameters>0)#
  {#
	  worst.pars	<- pars[, ans[order(NEFF)[1:control$pdf.plot.n.worst.case.parameters], VAR]]#
	  #	traces#
	  cat('\nPlotting traces for worst parameters...')#
	  p				<- mcmc_trace(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=1))#
	  pdf(file=paste0(control$outfile.base,'_worst_traces.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
#
	  #	histograms#
	  cat('\nPlotting marginal posterior densities for worst parameters...')#
	  p				<- mcmc_hist(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_worst_marginalposteriors.pdf'), w=10, h=control$pdf.height.per.par*ncol(worst.pars)/4)#
	  print(p)#
	  dev.off()#
#
	  #	autocorrelations#
	  cat('\nPlotting autocorrelations for worst parameters...')#
	  p				<- mcmc_acf_bar(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol = 1))#
	  pdf(file=paste0(control$outfile.base,'_worst_acf.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
  }#
}
infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"#
	infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	for(predict.with.infcounts in c(0,1))#
		for(predict.inflation in c(10,20,30))#
		{#
			RakaiFull.phylogeography.190327.predict.areaflows(	infile.inference.data=infile.inference.data, #
																infile.inference.mcmc=infile.inference.mcmc, #
																infile.subdistricts=infile.subdistricts, #
																predict.with.infcounts=predict.with.infcounts, #
																predict.inflation=predict.inflation)#
			gc()#
		}
RakaiFull.phylogeography.190327.predict.areaflows<- function(infile.inference.data=NULL, infile.inference.mcmc=NULL, infile.subdistricts=NULL, predict.with.infcounts=1, predict.inflation=10)#
{	#
	#predict.with.infcounts<- 1; predict.inflation<- 10#
	require(data.table)	#
	require(gtools)	#
	if(is.null(infile.inference.data))	#
		infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	if(is.null(infile.inference.mcmc))#
		infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"	#
	if(is.null(infile.subdistricts))		#
		infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	outfile.base						<- gsub('.rda$','',infile.inference.mcmc)#
	tmp									<- gsub('.*_opt([0-9]+).*','\\1',outfile.base)#
	#tmp									<- "112401"#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- as.integer(substr(tmp,1,1))#
	opt$adjust.participation.bias		<- as.integer(substr(tmp,2,2))#
	opt$migration.def.code				<- substr(tmp,3,4)#
	opt$set.missing.migloc.to.inland	<- as.integer(substr(tmp,5,5))#
	opt$set.missing.migloc.to.fishing	<- as.integer(substr(tmp,6,6))#
	opt$predict.with.infcounts			<- predict.with.infcounts#
	opt$predict.inflation				<- predict.inflation#
	cat('\ninfile.inference=',infile.inference.data)#
	cat('\ninfile.inference.mcmc=',infile.inference.mcmc)#
	cat('\ninfile.subdistricts=',infile.subdistricts)#
	cat('\nopt=',unlist(opt))			#
	##
	#	prepare data on observed transmission flows#
	##
	load(infile.inference.data)#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}	#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))	#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )	#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	calculate observed number of transmissions#
	dobsRCCS	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobsRCCS, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobsRCCS[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobsRCCS))]#
	##
	# 	prepare data on fishing / inland areas#
	#		#
	darea	<- desm[, list(	ELIGIBLE=sum(PART_EVER+PART_NEVER),#
							HIV_1516_YES=sum(HIV_1516_YES)#
							), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])#
	load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	rasdata	<- melt(rasdata, id.vars='AREA')#
	rasdata	<- rasdata[, list(EST=round(sum(value),d=0)), by=c('AREA','variable')]#
	set(rasdata, NULL, 'AREA', rasdata[, tolower(AREA)])#
	rasdata[, SEX:= gsub('([A-Z]+)_([A-Z])','\\2',variable)]#
	rasdata[, variable:= gsub('([A-Z]+)_([A-Z])','\\1',variable)]#
	rasdata	<- dcast.data.table(rasdata, AREA+SEX~variable, value.var='EST')#
	darea	<- merge(rasdata, darea, by=c('AREA','SEX'))#
	dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		dprior[, P:= pmin(1, P_HIV)]		#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		dprior[, P:= pmin(1, P_POP)]#
	}	#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	dprior	<- subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))#
	##
	#	make csv table for supplement#
	if(0)#
	{#
		df	<- unique(subset(dsubdis, select=c(AREA, SUBDISTRICT, SEX, COMM_NUM_A, COMM_ELIGIBLE, MAP_POPCOUNT)))	#
		df	<- df[, list(MAP_POPCOUNT=round(MAP_POPCOUNT[1]), RCCS_ELIGIBLE=sum(COMM_ELIGIBLE), RCCS_ELIGIBLE_P=sum(COMM_ELIGIBLE)/MAP_POPCOUNT[1], N_COMM=length(unique(COMM_NUM_A))), by=c('AREA','SUBDISTRICT','SEX')]#
		setkey(df, AREA, SUBDISTRICT, SEX )#
		df[, RCCS_LABEL:= paste0(RCCS_ELIGIBLE,' (',round(RCCS_ELIGIBLE_P*100,d=1),'%)')]#
		write.csv( subset(df, select=c(AREA, SUBDISTRICT, SEX, MAP_POPCOUNT, N_COMM, RCCS_LABEL)), row.names=FALSE, file=gsub('\\.rda','_table.csv',infile.subdistricts))#
	}#
	#	flows that we expect:#
	if(0)#
	{#
		s		<- c(0.2363956, 0.2631666, 0.3919308, 0.5427133)#
		s		<- c(0.16, 0.18, 1, 1)#
		pi		<- c(0.243,0.029,0.039,0.231,0.184,0.006,0.039,0.127)#
		pi		<- pi/sum(pi)#
		pistar	<- c( 	pi[1]/s[4]/s[3],  pi[2]/s[4]/s[1],  pi[3]/s[2]/s[3], pi[4]/s[2]/s[1],#
						pi[5]/s[3]/s[4],  pi[6]/s[3]/s[2],  pi[7]/s[1]/s[4], pi[8]/s[1]/s[2])#
		pistar <- pistar/sum(pistar)#
		c( (pistar[1]+pistar[5]), (pistar[2]+pistar[6]), (pistar[3]+pistar[7]), (pistar[4]+pistar[8]) )#
		(pistar[3]+pistar[7]) / (pistar[2]+pistar[6]) #
		# 'Fish:M','Fish:F',#
	}#
	##
	#	aggregate MCMC samples to areas #
	#	#
	daggregateTo	<- subset(dobsRCCS, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY))]#
	daggregateTo[, REC_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$REC_TRM_CATEGORY))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)		#
	control	<- list(	burnin.p=0.05, #
						thin=NA_integer_, #
						regex_pars='*')#
	mca		<- source.attribution.mcmc.aggregateToTarget(infile.inference.mcmc, daggregateTo, control=control)#
	mca		<- subset(mca, !grepl('external',TR_TARGETCAT))#
	setnames(mca, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs	<- unique(subset(mca, select=c(TR_TRM_CAT, REC_TRM_CAT)))#
	setkey(dobs, TR_TRM_CAT, REC_TRM_CAT)#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]	#
	mca		<- merge(dobs, mca, by=c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs[, TR_SAMPLING_CATEGORY:= TR_TRM_CAT]#
	dobs[, REC_SAMPLING_CATEGORY:= REC_TRM_CAT]#
	##
	#	run MCMC#
	##
	set.seed(42)#
	pp.n			<- 1e4#
	pp.burnin		<- 0.9#
	pp.sweeps		<- 1e2#
	mc				<- list()#
	mc[['pars']]	<- list()#
	mc$pars$Z_RCCS	<- matrix(NA, nrow=pp.n, ncol=nrow(dobs))#
	mc[['pp']]		<- vector('list',pp.n)#
	for(i in 1:pp.n)#
	{#
		##
		# 	sample Z among RCCS communities, and add to dobs as 'TRM_OBS'#
		##
		dobs[, TRM_OBS:=NULL]#
		tmp					<- subset(mca, VARIABLE=='Z' & SAMPLE==sample(max(mca$SAMPLE), 1))#
		setnames(tmp, 'VALUE', 'TRM_OBS')#
		tmp					<- subset(tmp, select=c(TRM_CAT_PAIR_ID, TRM_OBS))#
		dobs				<- merge(dobs, tmp, by='TRM_CAT_PAIR_ID')#
		cat('\nIteration', i,'\nSetting Z among RCCS communities to', dobs$TRM_OBS)#
		mc$pars$Z_RCCS[i,]	<- dobs$TRM_OBS#
		##
		#	run MCMC and return#
		##
		control			<- list( mcmc.n=9*pp.sweeps, verbose=0 )#
		mc[['pp']][[i]]	<- source.attribution.mcmc(dobs, dprior, control=control)#
		mc[['pp']][[i]][['it.info']][, PP_IT:= i]#
		gc()#
	}#
	#	collect variables and save#
	for(x in c('XI','XI_LP','S','S_LP','Z','PI','N'))#
		mc$pars[[x]]	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['pars']][[x]][seq.int(pp.sweeps*pp.burnin+1, pp.sweeps),,drop=FALSE]) )#
	mc$it.info	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['it.info']][seq.int(9*pp.sweeps*pp.burnin+1, 9*pp.sweeps),] ) )		#
	mc$dl		<- mc[['pp']][[1]][['dl']] #
	mc$dlt		<- mc[['pp']][[1]][['dlt']] #
	mc$dlu		<- mc[['pp']][[1]][['dlu']]#
	mc$time		<- sum(sapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['time']] ))#
	mc[['pp']]	<- NULL#
	str(mc[[1]])#
	gc()	#
	mcmc.file	<- paste0(outfile.base, opt$predict.with.infcounts, opt$predict.inflation, '_prAreas.rda')#
	save(mc, dobsRCCS, dprior, darea, daggregateTo, file=mcmc.file)#
	#	MCMC diagnostics#
	control		<- list(	burnin.p=0, #
			regex_pars='PI', #
			credibility.interval=0.95, #
			pdf.plot.all.parameters=TRUE, #
			pdf.plot.n.worst.case.parameters=0, #
			pdf.height.per.par=1.2, #
			outfile.base=gsub('\\.rda','',mcmc.file))#
	source.attribution.mcmc.diagnostics(mcmc.file, control=control)	#
	# 	make data.table in long format and calculate key quantities#
	colnames(mc$pars[['PI']])	<- paste0('PI-',seq_len(ncol(mc$pars[['PI']])))#
	pars	<- as.data.table(mc$pars[['PI']])#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
	tmp		<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CAT, REC_TRM_CAT))#
	setnames(tmp, c('TR_TRM_CAT','REC_TRM_CAT'), c('TR_TARGETCAT','REC_TARGETCAT'))#
	pars	<- merge(pars, tmp, by='TRM_CAT_PAIR_ID')#
	set(pars, NULL, c('TRM_CAT_PAIR_ID','variable'), NULL)#
	setnames(pars, colnames(pars), toupper(colnames(pars)))#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','_PIGender.csv',mcmc.file))		#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland:M/fishing:M', 'inland:M fishing:F', 'fishing:M inland:F'), c('inland:F/fishing:F', 'inland:F fishing:M', 'fishing:F inland:M')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PIGender.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PIGender.csv',mcmc.file), control)#
	#	aggregate to fish<->inland#
	setnames(pars, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	pars[, TR_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',TR_TRM_CAT)]#
	pars[, REC_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',REC_TRM_CAT)]#
	pars	<- pars[, list(VALUE=sum(VALUE)), by=c('TR_TARGETCAT','REC_TARGETCAT','VARIABLE','SAMPLE')]#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','PI.csv',mcmc.file))#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland/fishing', 'inland fishing', 'fishing inland')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PI.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PI.csv',mcmc.file), control)	#
}
infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"#
	infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	for(predict.with.infcounts in c(1,0))#
		for(predict.inflation in c(10,20,30))#
		{#
			RakaiFull.phylogeography.190327.predict.areaflows(	infile.inference.data=infile.inference.data, #
																infile.inference.mcmc=infile.inference.mcmc, #
																infile.subdistricts=infile.subdistricts, #
																predict.with.infcounts=predict.with.infcounts, #
																predict.inflation=predict.inflation)#
			gc()#
		}
gc()
require(mcmc)#
	require(bayesplot)
require(coda)
exp(-1376)
exp(-1.376)
remotes::install_github("GIScience/openrouteservice-r")
library(openrouteservice)#
	ors_api_key('5b3ce3597851110001cf6248128ca90686df404da73a130f7a66f3cf')
library(openrouteservice)
ors_api_key('5b3ce3597851110001cf6248128ca90686df404da73a130f7a66f3cf')
coordinates <- list(c(8.34234, 48.23424), c(8.34423, 48.26424))	#
	x <- ors_directions(coordinates)
x
x[['features']][[1]][['geometry']]
require(ggplot2)
require(data.table)
require(gtools)	#
	require(coda)#
	require(bayesplot)
lddirichlet_vector	<- function(x, nu){#
	ans	<- sum((nu - 1) * log(x)) + sum(lgamma(nu)) - lgamma(sum(nu))#
	stopifnot(is.finite(ans))#
	ans#
}#
#
#' @title Source attribution while adjusting for sampling bias#
#' @export#
#' @import data.table#
#' @importFrom gtools rdirichlet#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param dobs Data.table of observed number of transmission events for each transmission pair category.#
#' @param dprior Data.table of draws from the prior distribution of sampling probabilities.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"seed"}{Random number seed, for reproducibility.}#
#'  \item{"mcmc.n"}{Guide on the number of MCMC iterations. The actual number of iterations will be slightly larger, and a multiple of the number of iterations needed to complete one MCMC sweep through all free parameters.}#
#'  \item{"verbose"}{Flag to switch on/off verbose output.}#
#'  \item{"outfile"}{Full path name to which the MCMC output is saved to in RDA format, in an object called \code{mc}.}#
#' }#
#' @return NULL. MCMC output is written to an RDA file.#
source.attribution.mcmc	<- function(dobs, dprior, control=list(seed=42, mcmc.n=1e3, verbose=1, outfile='SAMCMCv190327.rda')){#
  #library(data.table); library(gtools)#
#
  dmode <- function(x) {#
    den <- density(x, kernel=c("gaussian"))#
    (den$x[den$y==max(den$y)])#
  }#
  ##
  # basic checks#
  ##
  if(!all(dobs$TR_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for TR_SAMPLING_CATEGORY')#
  if(!all(dobs$REC_SAMPLING_CATEGORY %in% dprior$SAMPLING_CATEGORY))#
	  stop('Did not find prior samples of a sampling category for REC_SAMPLING_CATEGORY')#
#
  ptm	<- Sys.time()#
  if('seed'%in%names(control))#
  {#
	  cat('\nSetting seed to',control$seed)#
	  set.seed(control$seed)#
  }#
#
  ##
  # set up mcmc#
  ##
  mc				<- list()#
  #	determine if the sampling probabilities are <1.#
  # If they are NOT, Z will be the same as TRM_OBS, and the algorithm only updates PI#
  mc$with.sampling	<- dprior[, list(ALL_ONE=all(P==1)), by='SAMPLING_CATEGORY'][, !all(ALL_ONE)]#
  mc$time			<- NA_real_#
  # construct look-up table so we know which transmission pair categories need to be updated#
  # at every MCMC iteration#
  tmp				<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_SAMPLING_CATEGORY, REC_SAMPLING_CATEGORY))#
  tmp				<- melt(tmp, id.vars='TRM_CAT_PAIR_ID', value.name='SAMPLING_CATEGORY', variable.name='WHO')#
  #	make data.table with unique sampling categories#
  mc$dlu			<- unique(subset(tmp, select=c(WHO, SAMPLING_CATEGORY)))#
  mc$dlu[, UPDATE_ID:= seq_len(nrow(mc$dlu))]#
  setkey(mc$dlu, UPDATE_ID)#
  # make data.table that maps UPDATE_IDs to TRM_CAT_PAIR_IDs#
  mc$dl				<- merge(mc$dlu, tmp, by=c('WHO','SAMPLING_CATEGORY'))#
  setkey(mc$dl, UPDATE_ID)#
  #	every transmission category pair needs to be updated at least one as we sweep through the sampling categories#
  # I don t think this is guaranteed, hence the check#
  if( !all(dobs$TRM_CAT_PAIR_ID %in% sort(unique(mc$dl$TRM_CAT_PAIR_ID))) )#
	  stop('Fatal error. Contact the package maintainer with your input data.')#
  # make data.table that maps TRM_CAT_PAIR_IDs to transmitter UPDATE_IDs and recipient UPDATE_IDs#
  mc$dlt			<- dcast.data.table(mc$dl, TRM_CAT_PAIR_ID~WHO, value.var='UPDATE_ID')#
  setnames(mc$dlt, c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY'), c('TR_UPDATE_ID','REC_UPDATE_ID'))#
  mc$dlt			<- merge(mc$dlt,subset(dobs,select=c('TRM_CAT_PAIR_ID','TRM_OBS')),by='TRM_CAT_PAIR_ID')#
  setkey(mc$dlt,TRM_CAT_PAIR_ID)#
#
  # make indexed lookup table for speed#
  update.info	<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
	  update.info[[i]]	<- mc$dl[UPDATE_ID==i,TRM_CAT_PAIR_ID]#
  }#
  # make indexed prior samples for speed#
  setkey(dprior,SAMPLING_CATEGORY)#
  dprior2		<- vector('list', nrow(mc$dlu))#
  for (i in 1:nrow(mc$dlu))#
  {#
    tmp				<- mc$dlu[UPDATE_ID==i,SAMPLING_CATEGORY]#
    dprior2[[i]]	<- dprior[J(tmp),nomatch=0L]#
  }#
  if(dprior[, max(SAMPLE)]>10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=dmode(P)),by=SAMPLING_CATEGORY]  #
  }#
  if(dprior[, max(SAMPLE)]<=10)#
  {#
	  dprior3   <- dprior[,list(EST_SAMPLING_RATE=median(P)),by=SAMPLING_CATEGORY]#
  }#
  dobs2   <- subset(dobs,select = c('TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY','TRM_CAT_PAIR_ID'))#
  setnames(dprior3,colnames(dprior3),paste0('TR_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='TR_SAMPLING_CATEGORY')#
  setnames(dprior3,colnames(dprior3),gsub('TR_','REC_',colnames(dprior3)))#
  dobs2   <- merge(dobs2,dprior3,by='REC_SAMPLING_CATEGORY')#
  dobs2[,EST_SAMPLING_RATE:=TR_EST_SAMPLING_RATE * REC_EST_SAMPLING_RATE]#
#
  mc$nprior			<- max(dprior$SAMPLE)#
  mc$sweep			<- nrow(mc$dlu)+1L#
  mc$nsweep			<- ceiling( control$mcmc.n/mc$sweep )#
  mc$n				<- mc$nsweep*mc$sweep#
  mc$pars			<- list()#
  mc$pars$LAMBDA	<- matrix(NA_real_, ncol=nrow(dobs), nrow=1)		#prior for proportions#
  mc$pars$XI		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # prior for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$XI_LP		<- matrix(NA_real_, ncol=mc$sweep-1L, nrow=mc$nsweep+1L) # log prior density for sampling in transmitter categories and sampling in recipient categories, concatenated#
  mc$pars$S			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # prior probability of sampling transmission pair categories#
  mc$pars$S_LP		<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) # log prior density of sampling transmission pair categories#
  mc$pars$Z			<- matrix(NA_integer_, ncol=nrow(dobs), nrow=mc$nsweep+1L) #augmented data#
  mc$pars$NU		<- NA_real_															#prior for N#
  mc$pars$N			<- matrix(NA_integer_, ncol=1, nrow=mc$nsweep+1L)							#total number of counts on augmented data#
  mc$pars$PI		<- matrix(NA_real_, ncol=nrow(dobs), nrow=mc$nsweep+1L)	#proportions#
  mc$it.info		<- data.table(	IT= seq.int(0,mc$n),#
									PAR_ID= rep(NA_integer_, mc$n+1L),#
									BLOCK= rep(NA_character_, mc$n+1L),#
									MHRATIO= rep(NA_real_, mc$n+1L),#
									ACCEPT=rep(NA_integer_, mc$n+1L),#
									LOG_LKL=rep(NA_real_, mc$n+1L),#
									LOG_PRIOR=rep(NA_real_, mc$n+1L))#
#
  if(1)#
  {#
	  cat('\nNumber of parameters:\t', ncol(mc$pars$PI)+ncol(mc$pars$N)+ncol(mc$pars$Z)+ncol(mc$pars$S)+ncol(mc$pars$XI) )#
	  cat('\nDimension of PI:\t', ncol(mc$pars$PI))#
	  cat('\nSweep length:\t', mc$sweep)#
	  cat('\nNumber of sweeps:\t', mc$nsweep)#
	  cat('\nNumber of iterations:\t', mc$n)#
	  tmp				<- mc$dl[, list(N_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
	  cat('\nNumber of transmission pair categories updated per iteration, and their frequencies:\n')#
	  print(table(tmp$N_PAIRS))#
  }#
  ##
  # initialise MCMC#
  ##
  mc$curr.it			<- 1L#
  set(mc$it.info, mc$curr.it, 'BLOCK', 'INIT')#
  set(mc$it.info, mc$curr.it, 'PAR_ID', 0L)#
  set(mc$it.info, mc$curr.it, 'MHRATIO', 1)#
  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
  #	prior lambda: use the Berger objective prior with minimal loss compared to marginal Beta reference prior#
  #	(https://projecteuclid.org/euclid.ba/1422556416)#
  mc$pars$LAMBDA[1,]	<- 0.8/nrow(dobs)#
  # prior for sampling in transmitter categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='TR_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in in recipient categories#
  tmp					<- subset(dprior, SAMPLE==sample(mc$nprior,1))#
  tmp					<- merge(unique(subset(mc$dl, WHO=='REC_SAMPLING_CATEGORY', c(SAMPLING_CATEGORY, UPDATE_ID))), tmp, by='SAMPLING_CATEGORY')#
  setkey(tmp, UPDATE_ID)#
  mc$pars$XI[1, tmp$UPDATE_ID]		<- tmp$P#
  mc$pars$XI_LP[1, tmp$UPDATE_ID]	<- tmp$LP#
  # prior for sampling in transmission pair categories#
  mc$pars$S[1,]			<- mc$pars$XI[1, mc$dlt$TR_UPDATE_ID] * mc$pars$XI[1, mc$dlt$REC_UPDATE_ID]#
  mc$pars$S_LP[1,]		<- mc$pars$XI_LP[1, mc$dlt$TR_UPDATE_ID] + mc$pars$XI_LP[1, mc$dlt$REC_UPDATE_ID]#
  #	augmented data: proposal draw under sampling probability#
  mc$pars$Z[1,]			<- dobs$TRM_OBS + rnbinom(nrow(dobs),dobs$TRM_OBS,mc$pars$S[1,])#
  #	prior nu: set Poisson rate to the expected augmented counts, under average sampling probability#
  mc$pars$NU			<- sum(dobs$TRM_OBS) / mean(dobs2$EST_SAMPLING_RATE)#
  #	total count: that s just the sum of Z#
  mc$pars$N[1,]			<- sum(mc$pars$Z[1,])#
  #	proportions: draw from full conditional#
  mc$pars$PI[1,]		<- rdirichlet(1, mc$pars$Z[1,] + mc$pars$LAMBDA[1,])#
  #	store log likelihood#
  tmp	<- sum( dbinom(dobs$TRM_OBS, size=mc$pars$Z[1,], prob=mc$pars$S[1,], log=TRUE) ) +#
    dmultinom(mc$pars$Z[1,], size=mc$pars$N[1,], prob=mc$pars$PI[1,], log=TRUE)#
  set(mc$it.info, 1L, 'LOG_LKL', tmp)#
  # 	store log prior#
  tmp	<- dpois(mc$pars$N[1,], lambda=mc$pars$NU, log=TRUE) +#
    		lddirichlet_vector(mc$pars$PI[1,], nu=mc$pars$LAMBDA[1,]) +#
    		sum(mc$pars$S_LP[1,])#
  set(mc$it.info, 1L, 'LOG_PRIOR', tmp)#
  # parameter value at the current step#
  XI.curr	<- mc$pars$XI[1,]#
  XI_LP.curr<- mc$pars$XI_LP[1,]#
  S.curr	<- mc$pars$S[1,]#
  S_LP.curr	<- mc$pars$S_LP[1,]#
  PI.curr	<- mc$pars$PI[1,]#
  N.curr	<- mc$pars$N[1,]#
  Z.curr	<- mc$pars$Z[1,]#
#
  # run mcmc#
  options(warn=0)#
  for(i in 1L:mc$n)#
  {#
    mc$curr.it		<- i#
    # determine source-recipient combination that will be updated in this iteration#
    update.count	<- (i-1L) %% mc$sweep + 1L#
    update.round 	<- (i-1L) %/% mc$sweep + 1L#
	# update in one go S, Z, N for the ith XI#
    if(mc$with.sampling & update.count<mc$sweep)#
    {#
	  # update.info	<- subset(mc$dl, UPDATE_ID==update.count)	# recompute for each sweep + the category and the pair id#
      update.cat	<- mc$dlu$SAMPLING_CATEGORY[update.count]#
      update.pairs	<- update.info[[update.count]]#
#
      # propose single XI#
	  XI.prop		<- XI.curr#
	  XI_LP.prop	<- XI_LP.curr#
	  tmp			<- dprior2[[update.count]][sample(mc$nprior,1),]#
	  if(tmp$SAMPLING_CATEGORY[1]!=update.cat)#
		  stop('\nFatal error in dprior2.')#
	  XI.prop[ update.count ]	<- tmp$P#
	  XI_LP.prop[ update.count ]<- tmp$LP#
	  # propose all S that involve the one XI from above#
	  S.prop						<- S.curr#
	  S_LP.prop						<- S_LP.curr#
	  S.prop[update.pairs]			<- XI.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] * XI.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  S_LP.prop[update.pairs]		<- XI_LP.prop[ mc$dlt$TR_UPDATE_ID[update.pairs] ] + XI_LP.prop[ mc$dlt$REC_UPDATE_ID[update.pairs] ]#
	  # propose all Z that involve a new S#
	  Z.prop						<- Z.curr#
	  Z.prop[update.pairs]			<- mc$dlt$TRM_OBS[update.pairs] + rnbinom(length(update.pairs), mc$dlt$TRM_OBS[update.pairs], S.prop[update.pairs])#
	  # propose total of Z#
	  N.prop						<- sum(Z.prop)#
	  #	calculate MH ratio#
	  log.prop.ratio	<- sum(dnbinom(Z.curr[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.curr[update.pairs], log=TRUE)) -#
						   sum(dnbinom(Z.prop[update.pairs]-mc$dlt$TRM_OBS[update.pairs], size=mc$dlt$TRM_OBS[update.pairs], prob=S.prop[update.pairs], log=TRUE))#
	  log.fc			<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.curr[update.pairs], prob=S.curr[update.pairs], log=TRUE)) +#
						   dmultinom(Z.curr, prob=PI.curr, log=TRUE) +#
						   dpois(N.curr, lambda=mc$pars$NU, log=TRUE)#
	  log.fc.prop		<- sum(dbinom(mc$dlt$TRM_OBS[update.pairs], size=Z.prop[update.pairs], prob=S.prop[update.pairs], log=TRUE)) +#
			  			   dmultinom(Z.prop, prob=PI.curr, log=TRUE) +#
			  			   dpois(N.prop, lambda=mc$pars$NU, log=TRUE)#
	  log.mh.ratio		<- log.fc.prop - log.fc + log.prop.ratio#
	  mh.ratio			<- min(1,exp(log.mh.ratio))#
	  #	update#
	  mc$curr.it		<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'S-Z-N')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', update.count)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', mh.ratio)#
	  accept 			<- as.integer(runif(1) < mh.ratio)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', accept)#
#
	  if(control$verbose & accept)#
	  {#
		  cat('\nit ',mc$curr.it,' ACCEPT S-Z-N block ',update.count)#
	  }#
	  if(accept)#
	  {#
		  XI.curr	<- XI.prop#
		  XI_LP.curr<- XI_LP.prop#
		  S.curr	<- S.prop#
		  S_LP.curr	<- S_LP.prop#
		  Z.curr	<- Z.prop#
		  N.curr	<- N.prop#
	  }#
    }#
#
    # update PI#
    if(!mc$with.sampling | update.count==mc$sweep)#
    {#
      #	propose#
      PI.prop		<- rdirichlet(1L, Z.curr + mc$pars$LAMBDA[1,])#
      #	this is the full conditional of PI given S, N, Z#
      #	always accept#
      #	update#
	  mc$curr.it	<- mc$curr.it+1L#
	  set(mc$it.info, mc$curr.it, 'BLOCK', 'PI')#
	  set(mc$it.info, mc$curr.it, 'PAR_ID', NA_integer_)#
	  set(mc$it.info, mc$curr.it, 'MHRATIO', 1L)#
	  set(mc$it.info, mc$curr.it, 'ACCEPT', 1L)#
      PI.curr		<- PI.prop#
#
	  # at the end of sweep, record current parameters#
      mc$pars$XI[update.round+1L,]		<- XI.curr#
	  mc$pars$XI_LP[update.round+1L,]	<- XI_LP.curr#
      mc$pars$S[update.round+1L,]		<- S.curr#
	  mc$pars$S_LP[update.round+1L,]	<- S_LP.curr#
      mc$pars$Z[update.round+1L,]		<- Z.curr#
      mc$pars$N[update.round+1L,]		<- N.curr#
      mc$pars$PI[update.round+1L,]		<- PI.curr#
    }#
#
	# 	record log likelihood#
	tmp	<- sum(dbinom(dobs$TRM_OBS, size=Z.curr, prob=S.curr, log=TRUE) ) +#
	    		dmultinom(Z.curr, size=N.curr, prob=PI.curr, log=TRUE)#
	set(mc$it.info, mc$curr.it, 'LOG_LKL', tmp)#
	# 	record log prior#
	tmp	<- dpois(N.curr, lambda=mc$pars$NU, log=TRUE) +#
	  			lddirichlet_vector(PI.curr, nu=mc$pars$LAMBDA[1,]) +#
			  	sum(S_LP.curr)#
	set(mc$it.info, mc$curr.it, 'LOG_PRIOR', tmp)#
	##
	if(update.count==mc$sweep & update.round %% 100 == 0){#
		cat('\nSweeps done:\t',update.round)#
	}#
  }#
#
  mc$time	<- Sys.time()-ptm#
  if(!'outfile'%in%names(control))#
	  return(mc)#
  save(mc,	file=control$outfile)#
  NULL#
}#
#
#' @title Aggregate MCMC output to target parameters#
#' @export#
#' @import data.table#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param daggregateTo Data.table that maps the categories of transmission pairs used in the MCMC to lower-dimensional categories that are of primary interest.#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"thin"}{Thin MCMC output to every nth MCMC iteration.}#
#'  \item{"regex_pars"}{Regular expression to select the parameters that are to be aggregated.}#
#'  \item{"outfile"}{Full file name of the output csv file.}#
#' }#
#' @return NULL. Monte Carlo samples are written to a csv file.#
source.attribution.mcmc.aggregateToTarget	<- function(mcmc.file, daggregateTo, control=list(burnin.p=NA_real_, thin=NA_integer_, regex_pars='*', outfile=gsub('\\.rda','_aggregated.csv',mcmc.file))){#
	#	basic checks#
	if(!'data.table'%in%class(daggregateTo))#
		stop('daggregateTo is not a data.table')#
	if(!all(c('TRM_CAT_PAIR_ID','TR_TARGETCAT','REC_TARGETCAT')%in%colnames(daggregateTo)))#
		stop('daggregateTo does not contain one of the required columns TRM_CAT_PAIR_ID, TR_TARGETCAT, REC_TARGETCAT')#
#
	#	load MCMC output#
	cat('\nLoading MCMC output...')#
	load(mcmc.file)#
#
	#	define internal control variables#
	burnin.p	<- control$burnin.p#
	if(is.na(burnin.p))#
		burnin.p<- 0#
	burnin.n	<- floor(burnin.p*nrow(mc$pars$S))#
	thin		<- control$thin#
	if(is.na(thin))#
		thin	<- 1#
#
	#	collect parameters#
	cat('\nCollecting parameters...')#
	pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
	if(grepl(control$regex_pars,'Z'))#
	{#
		tmp	<- mc$pars$Z#
		colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
	if(grepl(control$regex_pars,'PI'))#
	{#
		tmp	<- mc$pars$PI#
		colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
		pars	<- cbind(pars, tmp)#
	}#
#
	# remove burn-in#
	if(burnin.n>0)#
	{#
		cat('\nRemoving burnin in set to ', 100*burnin.p,'% of chain, total iterations=',burnin.n)#
		tmp		<- seq.int(burnin.n,nrow(mc$pars$S))#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	# thin#
	if(thin>1)#
	{#
		cat('\nThinning to every', thin,'th iteration')#
		tmp		<- seq.int(1,nrow(pars),thin)#
		pars	<- pars[tmp,,drop=FALSE]#
	}#
#
	cat('\nMaking aggregated MCMC output...')#
	# make data.table in long format#
	pars	<- as.data.table(pars)#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
#
	# aggregate MCMC samples#
	if(!all(sort(unique(pars$TRM_CAT_PAIR_ID))==sort(unique(daggregateTo$TRM_CAT_PAIR_ID))))#
		stop('The transmission count categories in the MCMC output do not match the transmission count categories in the aggregateTo data table.')#
	pars	<- merge(pars, daggregateTo, by='TRM_CAT_PAIR_ID')#
	pars	<- pars[, list(VALUE=sum(value)), by=c('VARIABLE','TR_TARGETCAT','REC_TARGETCAT','SAMPLE')]#
#
	# save or return#
	if(!'outfile'%in%names(control))#
		return(pars)#
	if(grepl('csv$',control$outfile))#
	{#
		cat('\nWriting csv file to',control$outfile)#
		write.csv(pars, row.names=FALSE, file=control$outfile)#
	}#
	if(grepl('rda$',control$outfile))#
	{#
		cat('\nSaving rda file to',control$outfile)#
		save(pars, file=control$outfile)#
	}#
}#
#
#' @title Estimate Flows, Sources, WAIFM, Flow ratios#
#' @export#
#' @import data.table#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param infile Full file name to aggregated MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the derivation of key quantities:#
#' \itemize{#
#'  \item{"quantiles"}{Named list of quantiles. Default: c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975)}#
#'  \item{"flowratios"}{Cector of length 3. First element: name of flow ratio. Second element: name of transmission pair category for enumerator of flow ratio. Third element: name of transmission pair category for denominator of flow ratio.}#
#'  \item{"outfile"}{Full file name for output csv file.}#
#' }#
#' @return NULL. A csv file is written to disk.#
source.attribution.aggmcmc.getKeyQuantities<- function(infile, control)#
{#
	cat('\nReading aggregated MCMC output...')#
	pars		<- as.data.table(read.csv(infile, stringsAsFactors=FALSE))#
	pars		<- subset(pars, VARIABLE=='PI')#
	if(any(is.na(pars$VALUE)))#
	{#
		cat('\nRemoving NA output for samples n=', nrow(subset(pars, is.na(VALUE))))#
		pars		<- subset(pars, !is.na(VALUE))#
	}#
	cat('\nComputing flows...')#
	#	calculate flows#
	z		<- pars[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='flows']#
	ans		<- copy(z)#
	gc()#
#
	cat('\nComputing WAIFM...')#
	#	calculate WAIFM#
	z		<- pars[, list(REC_TARGETCAT=REC_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('TR_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, TR_TARGETCAT, REC_TARGETCAT )#
	z[, STAT:='waifm']#
	ans		<- rbind(ans,z)#
	gc()#
#
	cat('\nComputing sources...')#
	#	calculate sources#
	z		<- pars[, list(TR_TARGETCAT=TR_TARGETCAT, VALUE=VALUE/sum(VALUE)), by=c('REC_TARGETCAT','SAMPLE')]#
	z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('TR_TARGETCAT','REC_TARGETCAT')]#
	z		<- dcast.data.table(z, TR_TARGETCAT+REC_TARGETCAT~P, value.var='Q')#
	z[, LABEL:= paste0(round(M*100, d=1), '%\n[',round(CL*100,d=1),'% - ',round(CU*100,d=1),'%]')]#
	z[, LABEL2:= paste0(round(M*100, d=1), '% (',round(CL*100,d=1),'%-',round(CU*100,d=1),'%)')]#
	setkey(z, REC_TARGETCAT, TR_TARGETCAT )#
	z[, STAT:='sources']#
	ans		<- rbind(ans,z)#
	gc()#
#
	if(length(control$flowratios)>0)#
	{#
		cat('\nComputing flow ratios...')#
		#	calculate transmission flow ratios#
		z		<- copy(pars)#
		z[, FLOW:=paste0(TR_TARGETCAT,' ',REC_TARGETCAT)]#
		z		<- dcast.data.table(z, SAMPLE~FLOW, value.var='VALUE')#
		set(z, NULL, colnames(z)[!colnames(z)%in%c('SAMPLE',unlist(control$flowratios))], NULL)#
		for(ii in seq_along(control$flowratios))#
		{#
			if(!control$flowratios[[ii]][2]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][2],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][2], 0)#
			}#
			if(!control$flowratios[[ii]][3]%in%colnames(z))#
			{#
				warning('\nColumn name ',control$flowratios[[ii]][3],' not in MCMC output. Setting to 0.')#
				set(z, NULL, control$flowratios[[ii]][3], 0)#
			}#
			set(z, NULL, control$flowratios[[ii]][1], z[[ control$flowratios[[ii]][2] ]] /  z[[ control$flowratios[[ii]][3] ]])#
			set(z, NULL, c(control$flowratios[[ii]][2],control$flowratios[[ii]][3]), NULL)#
		}#
		z		<- melt(z, id.vars='SAMPLE', value.name='VALUE', variable.name='FLOWRATIO_CAT')#
		z		<- z[, list(P=names(control$quantiles), Q=unname(quantile(VALUE, p=control$quantiles))), by=c('FLOWRATIO_CAT')]#
		z		<- dcast.data.table(z, FLOWRATIO_CAT~P, value.var='Q')#
		z[, LABEL:= paste0(round(M, d=2), '\n[',round(CL,d=2),' - ',round(CU,d=2),']')]#
		z[, LABEL2:= paste0(round(M, d=2), ' (',round(CL,d=2),'-',round(CU,d=2),')')]#
		z[, STAT:='flow_ratio']#
		ans		<- rbind(ans,z, fill=TRUE)#
		gc()#
	}#
#
	cat('\nWriting output to',control$outfile)#
	write.csv(ans, row.names=FALSE,file=control$outfile)#
}#
#' @title MCMC diagnostics for the source attribution algorithm#
#' @export#
#' @import data.table#
#' @import ggplot2#
#' @importFrom bayesplot mcmc_trace mcmc_acf_bar mcmc_hist#
#' @importFrom coda mcmc effectiveSize#
#' @author Xiaoyue Xi, Oliver Ratmann#
#' @param mcmc.file Full file name to MCMC output from function \code{source.attribution.mcmc}#
#' @param control List of input arguments that control the behaviour of the source attribution algorithm:#
#' \itemize{#
#'  \item{"burnin.p"}{Proportion of MCMC iterations that are removed as burn-in period.}#
#'  \item{"regex_pars"}{Regular expression to select the parameter names for which diagnostics are computed. The default is all parameters, which is '*'.}#
#'  \item{"credibility.interval"}{Width of the marginal posterior credibility intervals.}#
#'  \item{"pdf.plot.n.worst.case.parameters"}{Integer which specifies the number of parameters with smallest effective sample size that are inspected in detail. If set to 0, worst case analyses are not performed.}#
#'  \item{"pdf.plot.all.parameters"}{Flag which specifies if traces shall be plotted for all parameters. If set to TRUE, very large pdfs may be created.}#
#'  \item{"pdf.height.per.par"}{Most plots show diagnostics with parameters listed on the y-axis. This value controls the plot height in inches for each free parameter.}#
#'  \item{"outfile.base"}{Start of the full file name for all output files.}#
#' }#
#' @return NULL. Diagnostic plots and csv files are written to disk.#
source.attribution.mcmc.diagnostics	<- function(mcmc.file, control=list(burnin.p=0.2, regex_pars='*', credibility.interval=0.95, pdf.plot.n.worst.case.parameters=10, pdf.plot.all.parameters=FALSE, pdf.height.per.par=1.2, outfile.base=gsub('\\.rda','',mcmc.file))){#
  #library(coda); library(data.table); library(bayesplot); library(ggplot2)#
#
  cat('\nLoading MCMC output...')#
  load(mcmc.file)#
#
  burnin.n	<- floor(control$burnin.p*nrow(mc$pars$S))#
#
  cat('\nCollecting parameters...')#
  pars		<- matrix(NA,nrow=nrow(mc$pars$S),ncol=0)#
  if(grepl(control$regex_pars,'S'))#
  {#
	  tmp	<- mc$pars$S#
	  colnames(tmp)	<- paste0('S-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'Z'))#
  {#
	  tmp	<- mc$pars$Z#
	  colnames(tmp)	<- paste0('Z-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
  if(grepl(control$regex_pars,'N'))#
  {#
	  tmp	<- mc$pars$N#
	  colnames(tmp)	<- paste0('N-',1:ncol(tmp))#
	  pars	<- cbind(pars, tmp)#
  }#
 if(grepl(control$regex_pars,'PI'))#
 {#
	 tmp	<- mc$pars$PI#
	 colnames(tmp)	<- paste0('PI-',1:ncol(tmp))#
	 pars	<- cbind(pars, tmp)#
 }#
#
  #	traces for parameters#
  if(control$pdf.plot.all.parameters)#
  {#
	  cat('\nPlotting traces for all parameters...')#
	  p		<- mcmc_trace(pars, pars=colnames(pars), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_marginaltraces.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars))#
	  print(p)#
	  dev.off()#
  }#
#
  #	traces for log likelihood and log posterior#
  if(1)#
  {#
	  pars2				<- as.matrix(subset(mc$it.info, BLOCK=='PI', select=c(LOG_LKL, LOG_PRIOR)))#
	  pars2[,2]			<- pars2[,1]+pars2[,2] #
	  colnames(pars2)	<- c('log likelihood','log posterior')	  	    #
	  cat('\nPlotting log likelihood and log posterior...')#
	  p		<- mcmc_trace(pars2, pars=colnames(pars2), facet_args = list(ncol = 1), n_warmup=burnin.n)#
	  pdf(file=paste0(control$outfile.base,'_loglklpotrace.pdf'), w=7, h=control$pdf.height.per.par*ncol(pars2)*2)#
	  print(p)#
	  dev.off()	  #
	  p				<- mcmc_hist(pars2, pars=colnames(pars2), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_loglklpohist.pdf'), w=10, h=control$pdf.height.per.par*ncol(pars2))#
	  print(p)#
	  dev.off()	  #
  }#
#
  #	acceptance rate per MCMC update ID#
  cat('\nPlotting acceptance rates...')#
  da	<- subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, list(ACC_RATE=mean(ACCEPT)), by='PAR_ID']#
  setnames(da, 'PAR_ID', 'UPDATE_ID')#
  tmp	<- mc$dl[, list(N_TRM_CAT_PAIRS=length(TRM_CAT_PAIR_ID)), by='UPDATE_ID']#
  da	<- merge(da, tmp, by='UPDATE_ID')#
  ggplot(da, aes(x=N_TRM_CAT_PAIRS, y=ACC_RATE)) +#
		  geom_point() +#
		  theme_bw() +#
		  scale_y_continuous(label=scales::percent) +#
		  labs(	x='\nNumber of transmission pair categories updated per sampling category',#
				y='Acceptance rate\n')#
  ggsave(file=paste0(control$outfile.base,'_acceptance_per_updateID.pdf'), w=6, h=6)#
  cat('\nAverage acceptance rate= ',subset(mc$it.info, !is.na(PAR_ID) & PAR_ID>0)[, round(mean(ACCEPT), d=3)])#
  cat('\nUpdate IDs with lowest acceptance rates')#
  print( da[order(ACC_RATE)[1:10],] )#
#
  # remove burn-in#
  cat('\nRemoving burnin in set to ', 100*control$burnin.p,'% of chain, total iterations=',burnin.n)#
  tmp	<- seq.int(burnin.n+1L,nrow(mc$pars$S))#
  pars	<- pars[tmp,,drop=FALSE]#
#
  # effective sampling sizes#
  cat('\nCalculating effective sample size for all parameters...')#
  tmp	<- mcmc(pars)#
  ans	<- data.table(ID= seq_len(ncol(pars)), VAR= colnames(pars), NEFF=as.numeric(effectiveSize(tmp)))#
  set(ans, NULL, 'ID', ans[, factor(ID, labels=VAR)])#
  if(control$pdf.plot.all.parameters)#
  {#
	  ggplot(ans, aes(x=NEFF, y=ID)) +#
			  geom_point() +#
			  theme_bw() +#
			  labs(x='\neffective sample size', y='')#
	  ggsave(file=paste0(control$outfile.base,'_neff.pdf'), w=6, h=control$pdf.height.per.par*ncol(pars)*0.15, limitsize=FALSE)#
  }#
#
  # summarise mean, sd, quantiles#
  cat('\nCalculating posterior summaries for all parameters...')#
  tmp	<- apply(pars, 2, function(x) quantile(x, p=c((1-control$credibility.interval)/2, 0.5, control$credibility.interval+(1-control$credibility.interval)/2)))#
  tmp	<- data.table(	VAR= colnames(pars),#
		  				MEAN= apply(pars, 2, mean),#
						SD= apply(pars, 2, sd),#
		  				MEDIAN=tmp[2,],#
						CI_L=tmp[1,],#
						CI_U=tmp[3,])#
  ans	<- merge(tmp, ans, by='VAR')#
  cat('\nParameters with lowest effective samples')#
  print( ans[order(NEFF)[1:10],] )#
#
  # write to file#
  cat('\nWriting summary file to',paste0(control$outfile.base,'_summary.csv'))#
  setkey(ans, ID)#
  write.csv(ans, file=paste0(control$outfile.base,'_summary.csv'))#
#
  # plots for worst case parameters#
  if(control$pdf.plot.n.worst.case.parameters>0)#
  {#
	  worst.pars	<- pars[, ans[order(NEFF)[1:control$pdf.plot.n.worst.case.parameters], VAR]]#
	  #	traces#
	  cat('\nPlotting traces for worst parameters...')#
	  p				<- mcmc_trace(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=1))#
	  pdf(file=paste0(control$outfile.base,'_worst_traces.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
#
	  #	histograms#
	  cat('\nPlotting marginal posterior densities for worst parameters...')#
	  p				<- mcmc_hist(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol=4))#
	  pdf(file=paste0(control$outfile.base,'_worst_marginalposteriors.pdf'), w=10, h=control$pdf.height.per.par*ncol(worst.pars)/4)#
	  print(p)#
	  dev.off()#
#
	  #	autocorrelations#
	  cat('\nPlotting autocorrelations for worst parameters...')#
	  p				<- mcmc_acf_bar(worst.pars, pars=colnames(worst.pars), facet_args = list(ncol = 1))#
	  pdf(file=paste0(control$outfile.base,'_worst_acf.pdf'), w=7, h=control$pdf.height.per.par*ncol(worst.pars))#
	  print(p)#
	  dev.off()#
  }#
}
RakaiFull.phylogeography.190327.predict.areaflows<- function(infile.inference.data=NULL, infile.inference.mcmc=NULL, infile.subdistricts=NULL, predict.with.infcounts=1, predict.inflation=10)#
{	#
	#predict.with.infcounts<- 1; predict.inflation<- 20#
	require(data.table)	#
	require(gtools)	#
	require(coda)#
	require(bayesplot)#
	if(is.null(infile.inference.data))	#
		infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	if(is.null(infile.inference.mcmc))#
		infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"	#
	if(is.null(infile.subdistricts))		#
		infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"#
	outfile.base						<- gsub('.rda$','',infile.inference.mcmc)#
	tmp									<- gsub('.*_opt([0-9]+).*','\\1',outfile.base)#
	#tmp									<- "112401"#
	opt									<- list()#
	opt$adjust.sequencing.bias			<- as.integer(substr(tmp,1,1))#
	opt$adjust.participation.bias		<- as.integer(substr(tmp,2,2))#
	opt$migration.def.code				<- substr(tmp,3,4)#
	opt$set.missing.migloc.to.inland	<- as.integer(substr(tmp,5,5))#
	opt$set.missing.migloc.to.fishing	<- as.integer(substr(tmp,6,6))#
	opt$predict.with.infcounts			<- predict.with.infcounts#
	opt$predict.inflation				<- predict.inflation#
	cat('\ninfile.inference=',infile.inference.data)#
	cat('\ninfile.inference.mcmc=',infile.inference.mcmc)#
	cat('\ninfile.subdistricts=',infile.subdistricts)#
	cat('\nopt=',unlist(opt))			#
	##
	#	prepare data on observed transmission flows#
	##
	load(infile.inference.data)#
	rtr	<- copy(rtr3)#
	if(opt$migration.def.code=='06')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_05YR, REC_INMIGRATE_05YR, TR_COMM_NUM_A_MIG_05YR')#
		setnames(rtr, 'TR_INMIGRATE_05YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_05YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_05YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='12')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_1YR, REC_INMIGRATE_1YR, TR_COMM_NUM_A_MIG_1YR')#
		setnames(rtr, 'TR_INMIGRATE_1YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_1YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_1YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='24')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_2YR, REC_INMIGRATE_2YR, TR_COMM_NUM_A_MIG_2YR')#
		setnames(rtr, 'TR_INMIGRATE_2YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_2YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_2YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='36')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_3YR, REC_INMIGRATE_3YR, TR_COMM_NUM_A_MIG_3YR')#
		setnames(rtr, 'TR_INMIGRATE_3YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_3YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_3YR', 'TR_COMM_NUM_A_MIG')#
	}#
	if(opt$migration.def.code=='48')#
	{#
		cat('\nSource attribution analysis based on TR_INMIGRATE_4YR, REC_INMIGRATE_4YR, TR_COMM_NUM_A_MIG_4YR')#
		setnames(rtr, 'TR_INMIGRATE_4YR', 'TR_INMIGRATE')#
		setnames(rtr, 'REC_INMIGRATE_4YR', 'REC_INMIGRATE')#
		setnames(rtr, 'TR_COMM_NUM_A_MIG_4YR', 'TR_COMM_NUM_A_MIG')#
	}	#
	rtr	<- subset(rtr, select=c(	'PAIRID','TR_RID','TR_COMM_NUM','TR_COMM_NUM_A','TR_COMM_NUM_A_MIG',#
					'TR_SEX','TR_BIRTHDATE','TR_COMM_TYPE','TR_INMIG_LOC','TR_INMIGRATE',#
					'REC_RID','REC_COMM_NUM','REC_COMM_NUM_A',#
					'REC_SEX','REC_BIRTHDATE','REC_COMM_TYPE','REC_INMIGRATE'))	#
	# inmigrant status#
	rtr[, TR_INMIGRANT:= as.integer(TR_INMIGRATE!='resident')]#
	rtr[, REC_INMIGRANT:= as.integer(grepl('inmigrant',REC_INMIGRATE))]#
	set(rtr, NULL, 'TR_COMM_NUM_A_MIG', rtr[, gsub('[0-9]+','',TR_COMM_NUM_A_MIG)])#
	#	set unknown origin to either fishing or inland#
	tmp	<- rtr[, which(TR_INMIGRATE=='inmigrant_from_unknown')]#
	if(opt$set.missing.migloc.to.inland)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_inland')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'imig')#
	}		#
	if(opt$set.missing.migloc.to.fishing)#
	{#
		set(rtr, tmp, 'TR_INMIGRATE', 'inmigrant_from_fisherfolk')#
		set(rtr, tmp, 'TR_COMM_NUM_A_MIG', 'fmig')#
	}#
	# add age #
	rtr[,TR_AGE_AT_MID:=2013.25-TR_BIRTHDATE]#
	rtr[,REC_AGE_AT_MID:=2013.25-REC_BIRTHDATE]#
	# impute age#
	tmp	<- which(is.na(rtr$TR_AGE_AT_MID))#
	set(rtr, tmp, 'TR_AGE_AT_MID', mean(rtr$TR_AGE_AT_MID[which(!is.na(rtr$TR_AGE_AT_MID))]) )#
	tmp	<- which(is.na(rtr$REC_AGE_AT_MID))#
	set(rtr, tmp, 'REC_AGE_AT_MID', mean(rtr$REC_AGE_AT_MID[which(!is.na(rtr$REC_AGE_AT_MID))]) )#
	# fixup from latest surveillance data#
	set(rtr, rtr[,which(TR_RID=="C036808")], 'TR_AGE_AT_MID', 39.946)	#
	set(rtr, rtr[,which(REC_RID=="G036802")], 'REC_AGE_AT_MID',	44.946)	#
	set(rtr, rtr[, which(REC_RID=="H103745")], 'REC_AGE_AT_MID', 20.42)	#
	set(rtr, rtr[, which(REC_RID=="C121534")],'REC_AGE_AT_MID', 28.549)#
	#	stratify age#
	rtr[, TR_AGE_AT_MID_C:= as.character(cut(TR_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	rtr[, REC_AGE_AT_MID_C:= as.character(cut(REC_AGE_AT_MID, breaks=c(10,25,35,65), labels=c('15-24','25-34','35+'), right=FALSE))]#
	stopifnot( nrow(subset(rtr, is.na(TR_AGE_AT_MID_C)))==0 )#
	stopifnot( nrow(subset(rtr, is.na(REC_AGE_AT_MID_C)))==0 )	#
	#	build category to match with sampling data tables #
	rtr[, REC_SAMPLING_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_SAMPLING_CATEGORY:= paste0(TR_COMM_NUM_A,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	build transmission flow category #
	rtr[, REC_TRM_CATEGORY:= paste0(REC_COMM_NUM_A,':',REC_SEX,':',REC_AGE_AT_MID_C,':',REC_INMIGRANT)]#
	rtr[, TR_TRM_CATEGORY:= paste0(TR_COMM_NUM_A_MIG,':',TR_SEX,':',TR_AGE_AT_MID_C,':',TR_INMIGRANT)]#
	#	calculate observed number of transmissions#
	dobsRCCS	<- rtr[, list( TRM_OBS=length(unique(PAIRID))), by=c('TR_TRM_CATEGORY','REC_TRM_CATEGORY','TR_SAMPLING_CATEGORY','REC_SAMPLING_CATEGORY')]#
	setkey(dobsRCCS, TR_TRM_CATEGORY, REC_TRM_CATEGORY )	#
	dobsRCCS[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobsRCCS))]#
	##
	# 	prepare data on fishing / inland areas#
	#		#
	darea	<- desm[, list(	ELIGIBLE=sum(PART_EVER+PART_NEVER),#
							HIV_1516_YES=sum(HIV_1516_YES)#
							), by=c('COMM_TYPE','SEX')]#
	setnames(darea, 'COMM_TYPE', 'AREA')#
	set(darea, NULL, 'AREA', darea[, gsub('fisherfolk','fishing',AREA)])#
	load(infile.subdistricts)#
	rasdata	<- as.data.table(rasdata)#
	rasdata[, POPCOUNT_M:= male_count]#
	rasdata[, POPCOUNT_F:= popcount_15_49-male_count]#
	rasdata[, HIVCOUNT_M:= hiv_count*0.4]#
	rasdata[, HIVCOUNT_F:= hiv_count*0.6]	#
	rasdata	<- subset(rasdata, select=c(pop_class, POPCOUNT_M,  POPCOUNT_F, HIVCOUNT_M, HIVCOUNT_F))#
	setnames(rasdata, colnames(rasdata), gsub('POP_CLASS','AREA',toupper(colnames(rasdata))))#
	rasdata	<- melt(rasdata, id.vars='AREA')#
	rasdata	<- rasdata[, list(EST=round(sum(value),d=0)), by=c('AREA','variable')]#
	set(rasdata, NULL, 'AREA', rasdata[, tolower(AREA)])#
	rasdata[, SEX:= gsub('([A-Z]+)_([A-Z])','\\2',variable)]#
	rasdata[, variable:= gsub('([A-Z]+)_([A-Z])','\\1',variable)]#
	rasdata	<- dcast.data.table(rasdata, AREA+SEX~variable, value.var='EST')#
	darea	<- merge(rasdata, darea, by=c('AREA','SEX'))#
	dprior	<- copy(darea)#
	dprior[, SAMPLING_CATEGORY:=paste0(AREA,':',SEX)]#
	##
	if(opt$predict.inflation>10)#
	{#
		cat('\nInflate counts by',opt$predict.inflation/10)#
		tmp	<- dprior[, which(AREA=='fishing')]#
		set(dprior, tmp, 'POPCOUNT', dprior[tmp, round(POPCOUNT * opt$predict.inflation/10)])#
		set(dprior, tmp, 'HIVCOUNT', dprior[tmp, round(HIVCOUNT * opt$predict.inflation/10)])#
	}#
	dprior[, P_POP:= ELIGIBLE/POPCOUNT]#
	dprior[, P_HIV:= HIV_1516_YES/HIVCOUNT]#
	if(opt$predict.with.infcounts==1)#
	{#
		cat('\nUse HIV counts for scaling')#
		dprior[, P:= pmin(1, P_HIV)]		#
	}#
	if(opt$predict.with.infcounts==0)#
	{#
		cat('\nUse population counts for scaling')#
		dprior[, P:= pmin(1, P_POP)]#
	}	#
	dprior[, LP:= 0]#
	dprior[, SAMPLE:= 1L]#
	dprior	<- subset(dprior, select=c(SAMPLING_CATEGORY, P, LP, SAMPLE))#
	##
	#	make csv table for supplement#
	if(0)#
	{#
		df	<- unique(subset(dsubdis, select=c(AREA, SUBDISTRICT, SEX, COMM_NUM_A, COMM_ELIGIBLE, MAP_POPCOUNT)))	#
		df	<- df[, list(MAP_POPCOUNT=round(MAP_POPCOUNT[1]), RCCS_ELIGIBLE=sum(COMM_ELIGIBLE), RCCS_ELIGIBLE_P=sum(COMM_ELIGIBLE)/MAP_POPCOUNT[1], N_COMM=length(unique(COMM_NUM_A))), by=c('AREA','SUBDISTRICT','SEX')]#
		setkey(df, AREA, SUBDISTRICT, SEX )#
		df[, RCCS_LABEL:= paste0(RCCS_ELIGIBLE,' (',round(RCCS_ELIGIBLE_P*100,d=1),'%)')]#
		write.csv( subset(df, select=c(AREA, SUBDISTRICT, SEX, MAP_POPCOUNT, N_COMM, RCCS_LABEL)), row.names=FALSE, file=gsub('\\.rda','_table.csv',infile.subdistricts))#
	}#
	#	flows that we expect:#
	if(0)#
	{#
		s		<- c(0.2363956, 0.2631666, 0.3919308, 0.5427133)#
		s		<- c(0.16, 0.18, 1, 1)#
		pi		<- c(0.243,0.029,0.039,0.231,0.184,0.006,0.039,0.127)#
		pi		<- pi/sum(pi)#
		pistar	<- c( 	pi[1]/s[4]/s[3],  pi[2]/s[4]/s[1],  pi[3]/s[2]/s[3], pi[4]/s[2]/s[1],#
						pi[5]/s[3]/s[4],  pi[6]/s[3]/s[2],  pi[7]/s[1]/s[4], pi[8]/s[1]/s[2])#
		pistar <- pistar/sum(pistar)#
		c( (pistar[1]+pistar[5]), (pistar[2]+pistar[6]), (pistar[3]+pistar[7]), (pistar[4]+pistar[8]) )#
		(pistar[3]+pistar[7]) / (pistar[2]+pistar[6]) #
		# 'Fish:M','Fish:F',#
	}#
	##
	#	aggregate MCMC samples to areas #
	#	#
	daggregateTo	<- subset(dobsRCCS, select=c(TRM_CAT_PAIR_ID, TR_TRM_CATEGORY, REC_TRM_CATEGORY))#
	daggregateTo[, TR_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$TR_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$TR_TRM_CATEGORY))]#
	daggregateTo[, REC_TARGETCAT:= paste0(	gsub('^e$','external',gsub('^f$','fishing',gsub('^a|i|t$','inland',substring(daggregateTo$REC_TRM_CATEGORY,1,1)))),#
					':',#
					gsub('^[a-z]+:([FM]):.*','\\1',daggregateTo$REC_TRM_CATEGORY))]#
	set(daggregateTo, NULL, c('TR_TRM_CATEGORY','REC_TRM_CATEGORY'), NULL)		#
	control	<- list(	burnin.p=0.05, #
						thin=NA_integer_, #
						regex_pars='*')#
	mca		<- source.attribution.mcmc.aggregateToTarget(infile.inference.mcmc, daggregateTo, control=control)#
	mca		<- subset(mca, !grepl('external',TR_TARGETCAT))#
	setnames(mca, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs	<- unique(subset(mca, select=c(TR_TRM_CAT, REC_TRM_CAT)))#
	setkey(dobs, TR_TRM_CAT, REC_TRM_CAT)#
	dobs[, TRM_CAT_PAIR_ID:= seq_len(nrow(dobs))]	#
	mca		<- merge(dobs, mca, by=c('TR_TRM_CAT','REC_TRM_CAT'))#
	dobs[, TR_SAMPLING_CATEGORY:= TR_TRM_CAT]#
	dobs[, REC_SAMPLING_CATEGORY:= REC_TRM_CAT]#
	##
	#	run MCMC#
	##
	set.seed(42)#
	pp.n			<- 1e4#
	pp.burnin		<- 0.9#
	pp.sweeps		<- 1e2#
	mc				<- list()#
	mc[['pars']]	<- list()#
	mc$pars$Z_RCCS	<- matrix(NA, nrow=pp.n, ncol=nrow(dobs))#
	mc[['pp']]		<- vector('list',pp.n)#
	for(i in 1:pp.n)#
	{#
		##
		# 	sample Z among RCCS communities, and add to dobs as 'TRM_OBS'#
		##
		dobs[, TRM_OBS:=NULL]#
		tmp					<- subset(mca, VARIABLE=='Z' & SAMPLE==sample(max(mca$SAMPLE), 1))#
		setnames(tmp, 'VALUE', 'TRM_OBS')#
		tmp					<- subset(tmp, select=c(TRM_CAT_PAIR_ID, TRM_OBS))#
		dobs				<- merge(dobs, tmp, by='TRM_CAT_PAIR_ID')#
		cat('\nIteration', i,'\nSetting Z among RCCS communities to', dobs$TRM_OBS)#
		mc$pars$Z_RCCS[i,]	<- dobs$TRM_OBS#
		##
		#	run MCMC and return#
		##
		control			<- list( mcmc.n=9*pp.sweeps, verbose=0 )#
		mc[['pp']][[i]]	<- source.attribution.mcmc(dobs, dprior, control=control)#
		mc[['pp']][[i]][['it.info']][, PP_IT:= i]#
		gc()#
	}#
	#	collect variables and save#
	for(x in c('XI','XI_LP','S','S_LP','Z','PI','N'))#
		mc$pars[[x]]	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['pars']][[x]][seq.int(pp.sweeps*pp.burnin+1, pp.sweeps),,drop=FALSE]) )#
	mc$it.info	<- do.call(rbind, lapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['it.info']][seq.int(9*pp.sweeps*pp.burnin+1, 9*pp.sweeps),] ) )		#
	mc$dl		<- mc[['pp']][[1]][['dl']] #
	mc$dlt		<- mc[['pp']][[1]][['dlt']] #
	mc$dlu		<- mc[['pp']][[1]][['dlu']]#
	mc$time		<- sum(sapply(seq_len(pp.n), function(i) mc[['pp']][[i]][['time']] ))#
	mc[['pp']]	<- NULL#
	str(mc[[1]])#
	gc()	#
	mcmc.file	<- paste0(outfile.base, opt$predict.with.infcounts, opt$predict.inflation, '_prAreas.rda')#
	save(mc, dobsRCCS, dprior, darea, daggregateTo, file=mcmc.file)#
	#	MCMC diagnostics#
	control		<- list(	burnin.p=0, #
			regex_pars='PI', #
			credibility.interval=0.95, #
			pdf.plot.all.parameters=TRUE, #
			pdf.plot.n.worst.case.parameters=0, #
			pdf.height.per.par=1.2, #
			outfile.base=gsub('\\.rda','',mcmc.file))#
	source.attribution.mcmc.diagnostics(mcmc.file, control=control)	#
	# 	make data.table in long format and calculate key quantities#
	colnames(mc$pars[['PI']])	<- paste0('PI-',seq_len(ncol(mc$pars[['PI']])))#
	pars	<- as.data.table(mc$pars[['PI']])#
	pars[, SAMPLE:= seq_len(nrow(pars))]#
	pars	<- melt(pars, id.vars='SAMPLE')#
	pars[, VARIABLE:= pars[, gsub('([A-Z]+)-([0-9]+)','\\1',variable)]]#
	pars[, TRM_CAT_PAIR_ID:= pars[, as.integer(gsub('([A-Z]+)-([0-9]+)','\\2',variable))]]#
	tmp		<- subset(dobs, select=c(TRM_CAT_PAIR_ID, TR_TRM_CAT, REC_TRM_CAT))#
	setnames(tmp, c('TR_TRM_CAT','REC_TRM_CAT'), c('TR_TARGETCAT','REC_TARGETCAT'))#
	pars	<- merge(pars, tmp, by='TRM_CAT_PAIR_ID')#
	set(pars, NULL, c('TRM_CAT_PAIR_ID','variable'), NULL)#
	setnames(pars, colnames(pars), toupper(colnames(pars)))#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','_PIGender.csv',mcmc.file))		#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland:M/fishing:M', 'inland:M fishing:F', 'fishing:M inland:F'), c('inland:F/fishing:F', 'inland:F fishing:M', 'fishing:F inland:M')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PIGender.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PIGender.csv',mcmc.file), control)#
	#	aggregate to fish<->inland#
	setnames(pars, c('TR_TARGETCAT','REC_TARGETCAT'), c('TR_TRM_CAT','REC_TRM_CAT'))#
	pars[, TR_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',TR_TRM_CAT)]#
	pars[, REC_TARGETCAT:= gsub('^([a-z]+)\\:([MF])$','\\1',REC_TRM_CAT)]#
	pars	<- pars[, list(VALUE=sum(VALUE)), by=c('TR_TARGETCAT','REC_TARGETCAT','VARIABLE','SAMPLE')]#
	write.csv(pars, row.names=FALSE, file=gsub('\\.rda','_PI.csv',mcmc.file))#
	control		<- list(	quantiles= c('CL'=0.025,'IL'=0.25,'M'=0.5,'IU'=0.75,'CU'=0.975),#
			flowratios= list( c('inland/fishing', 'inland fishing', 'fishing inland')),#
			outfile=gsub('\\.csv','_flowsetc.csv',gsub('\\.rda','_PI.csv',mcmc.file)))#
	source.attribution.aggmcmc.getKeyQuantities(gsub('\\.rda','_PI.csv',mcmc.file), control)	#
}
predict.with.infcounts<- 0
infile.inference.data			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_data_with_inmigrants.rda"#
	infile.inference.mcmc			<- "~/Dropbox (SPH Imperial College)/Rakai Fish Analysis/full_run/RakaiAll_output_190327_w250_s20_p25_d50_stagetwo_rerun23_min30_conf60_phylogeography_samcmc190327_nsweep1e5_opt112401.rda"#
	infile.subdistricts				<- "~/Dropbox (SPH Imperial College)/Rakai Pangea Meta Data/Data for Fish Analysis Working Group/Raster_HIVandPopcounts.rda"
for(predict.inflation in c(10,20,30))#
		{#
			RakaiFull.phylogeography.190327.predict.areaflows(	infile.inference.data=infile.inference.data, #
																infile.inference.mcmc=infile.inference.mcmc, #
																infile.subdistricts=infile.subdistricts, #
																predict.with.infcounts=predict.with.infcounts, #
																predict.inflation=predict.inflation)#
			gc()#
		}
require(pkgdown)
build_site('~/git/phyloscanner/phyloflows')
require(phyloflows)
data(twoGroupFlows1_mcmc, package="phyloflows")
outfile.base <- file.path(getwd(),'twoGroupFlows1_mcmc_') #
control <- list( burnin.p=0.05, #
                 regex_pars='*', #
				 credibility.interval=0.95, #
				 pdf.plot.all.parameters=FALSE, #
				 pdf.plot.n.worst.case.parameters=10, #
				 pdf.height.per.par=1.2, #
				 outfile.base=outfile.base)
control
require(data.table)#
require(phyloflows)
phyloflow:::source.attribution.mcmc.diagnostics(mc, control=control)
phyloflows:::source.attribution.mcmc.diagnostics(mc, control=control)
phyloflows:::source.attribution.mcmc.diagnostics(mc=mc, control=control)
build_articles('~/git/phyloscanner/phyloflows')
build_article('~/git/phyloscanner/phyloflows')
require(pkgdown)
build_site('~/git/phyloscanner/phyloflows')
require(pkgdown)
setwd("/Users/Oliver/git/phyloscanner/phyloflows")
build_articles()
require(phyloflows)
build_articles()
